{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit\n",
    "Steven Bird, mEwan Klein, and Edward Loper\n",
    "http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 03 - Writing Structured Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1 Back to the Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment would seem to be the most elementary programming concept, not deserving a separate discussion. However, there are some surprising subtleties here. Consider the following code fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = 'Monty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = ['Monty', ' Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[1] = 'Bdokin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Bdokin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = [empty, empty, empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested[1].append('Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = [[]] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested[1].append('Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested[1] = ['Monty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides two ways to check that a pair of items are the same. The is operator tests for object identity. We can use it to verify our earlier observations about objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "python = ['Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake_nest = [python] *size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] ==snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = random.choice(range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake_nest[position] = ['Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] ==snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1856308313352, 1856308313352, 1856309277192, 1856308313352, 1856308313352]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the condition part of an if statement, a non-empty string or list is evaluated as true,while an empty string or list evaluates as false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = ['cat', '', ['dog'], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "for element in mixed:\n",
    "    if element:\n",
    "        print (element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals=['cat','dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if 'cat' in animals:\n",
    "    print (1)\n",
    "elif 'dog' in animals:\n",
    "    print (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['No', 'good', 'fish','goes','anywhere','without','a','porpoise','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen two kinds of sequence object: strings and lists. Another kind of sequence is called a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'walk', 'fem', 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'fem', 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fem', 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'I turned off the spectroroute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (6, 'turned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[-3:], text[-3:], pair[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'off', 'turned', 'I', 'spectroroute']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'off', 'turned', 'I', 'spectroroute']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in set(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on Sequence Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'Red lorry, yellow, lorry, red lorry, yellow lorry.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red', 'lorry', ',', 'yellow', 'red', '.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(fdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['I', 'tumed', 'off', 'the', 'spectroroute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[2], words[3], words[4] = words[3], words[4], words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'tumed', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[2] = words[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[3] = words[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[4] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['I', 'tumed', 'the', 'spectroroute', 'off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1b045f10fc8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'tumed'), (2, 'the'), (3, 'spectroroute'), (4, 'off')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.nps_chat.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(0.9 * len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Different Sequence Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s combine our knowledge of these three sequence types, together with list comprehensions,to perform the task of sorting the words in a string by their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'I turned off the spectroroute'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlens = [(len(word), word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(w for(_,w) in wordlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = [('the', 'det', ['Di:', 'D@']),('off', 'prep', ['Qf', 'O:f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = tuple(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-f0ef1dd8cf20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlexicon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "lexicon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-e4e3a95fe95b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlexicon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'turned'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m't3:nd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m't3`nd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object doesn't support item deletion",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-0ba66aa11bf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object doesn't support item deletion"
     ]
    }
   ],
   "source": [
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve been making heavy use of list comprehensions, for compact and readable processing of texts. Here’s an example where we tokenize and normalize a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\"\"When I use a word,\"Humpty Dumpty said in rather a scornful tone,\"it means just what I choose it to mean - neither more nor less.\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " '``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " \"''\",\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\",\n",
       " \"''\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(w.lower() for w in nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Questions of Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming is as much an art as a science. The undisputed “bible” of programming,a 2,500 page multivolume work by Donald Knuth, is called The Art of Computer Programming.Many books have been written on Literate Programming, recognizing that humans, not just computers, must read and understand programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Coding Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing programs you make many subtle choices about names, spacing, comments,and so on. When you look at code written by other people, needless differences in style make it harder to interpret the code. Therefore, the designers of the Python language have published a style guide for Python code, available at http://www.python.org/dev/peps/pep-0008/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_word_pairs = [(cv,w) for w in rotokas_words \n",
    "                 for cv in re.findall('[ptksvr][aeiou]',w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = nltk.ConditionalFreqDist(\n",
    "    (genre,word) \n",
    "    for genre in brown.categories() \n",
    "    for word in brown.words(categories=genre)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_words = ['aaahhhh','ah','ahah','ahahah','ahhahahaha',\n",
    "            'ahhh','ahhhh', 'ahhhhhh','ahhhhhhhhhhhh','ha',\n",
    "            'haaa','hah','haha','hahaaa','hahah','hahaha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = ['aaaaa', 'bbbb', 'ccccc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(syllables) > 4 and len(syllables[2]) == 3 and \n",
    "    syllables[2][2] in [aeiou] and syllables[2][3] == syllables[1][3]):\n",
    "    process(syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(syllables) > 4 and len(syllables[2]) == 3 and \\\n",
    "syllables[2][2] in [aeiou] and syllables[2][3]==syllables[1][3]:\n",
    "    process(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedural Versus Declarative Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just seen how the same task can be performed in different ways, with implications for efficiency. Another factor influencing program development is programming style. Consider the following program to compute the average length of words in the Brown Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.corpus.brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for token in tokens:\n",
    "    count += 1\n",
    "    total += len(token)\n",
    "print(total / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "total = sum(len(t) for t in tokens)\n",
    "print(total / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "len_word_list = len(word_list)\n",
    "i=0\n",
    "while i < len(tokens):\n",
    "    j = 0\n",
    "    while j<len_word_list and word_list[j] < tokens[i]:\n",
    "        j += 1\n",
    "    if j==0 or token[i] != word_list[j]:\n",
    "        word_list.insert(j, tokens[i])\n",
    "        len_word_list += 1\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   0.63% The\n",
      "  2   0.63% Fulton\n",
      "  3   0.63% County\n",
      "  4   0.64% Grand\n",
      "  5   0.64% Jury\n",
      "  6   0.80% said\n",
      "  7   0.81% Friday\n",
      "  8   1.11% an\n",
      "  9   1.12% investigation\n",
      " 10   4.22% of\n",
      " 11   4.22% Atlanta's\n",
      " 12   4.24% recent\n",
      " 13   4.25% primary\n",
      " 14   4.25% election\n",
      " 15   4.26% produced\n",
      " 16   5.02% ``\n",
      " 17   5.18% no\n",
      " 18   5.19% evidence\n",
      " 19   5.95% ''\n",
      " 20   6.83% that\n",
      " 21   6.94% any\n",
      " 22   6.94% irregularities\n",
      " 23   6.98% took\n",
      " 24   7.03% place\n",
      " 25  11.28% .\n",
      " 26  11.28% jury\n",
      " 27  11.30% further\n",
      " 28  12.98% in\n",
      " 29  12.98% term-end\n",
      " 30  12.98% presentments\n",
      " 31  18.38% the\n",
      " 32  18.39% City\n",
      " 33  18.39% Executive\n",
      " 34  18.40% Committee\n",
      " 35  23.42% ,\n",
      " 36  23.73% which\n",
      " 37  24.17% had\n",
      " 38  24.17% over-all\n",
      " 39  24.18% charge\n",
      " 40  24.18% deserves\n",
      " 41  24.18% praise\n",
      " 42  26.59% and\n"
     ]
    }
   ],
   "source": [
    "for rank, word in enumerate(fd):\n",
    "    cumulative += fd[word] * 100 / fd.N()\n",
    "    print(\"%3d %6.2f%% %s\" % (rank+1, cumulative,word))\n",
    "    if cumulative > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "        longest = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(len(word) for word in text)\n",
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Legitimate Users for Counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are cases where we still want to use loop variables in a list comprehension. For example, we need to use a loop variable to extract successive overlapping n-grams from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[i:i+n] for i in range(len(sent) - n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = 3, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[set() for i in range(n)] for j in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[2][5].add('Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), {'Alice'}, set()]]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[set()] * n] * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[2][5].add(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
       " [{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
       " [{7}, {7}, {7}, {7}, {7}, {7}, {7}]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Functions:The Foundation of Structured Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions provide an effective way to package and reuse program code. For example, suppose we find that we often want to read text from an HTML file. This involves several steps: opening the file, reading it in, normalizing whitespace, and stripping HTML markup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file):\n",
    "    '\"\"\"Read text from a file, normalizing whitespace and stripping HTML markup\"\"\"'\n",
    "    text = open(file).read()\n",
    "    text = re.sub('\\s','', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_text in module __main__:\n",
      "\n",
      "get_text(file)\n",
      "    \"\"\"Read text from a file, normalizing whitespace and stripping HTML markup\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Inputs and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass information to functions using a function’s parameters, the parenthesized list of variables and constants following the function’s name in the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(msg, num):\n",
    "    return ''.join([msg] * num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = 'Monty Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty PythonMonty PythonMonty Python'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(monty, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monty():\n",
    "    return \"Monty Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty PythonMonty PythonMonty Python'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(monty(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty PythonMonty PythonMonty Python'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat('Monty Python', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort1(mylist):\n",
    "    mylist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort2(mylist):\n",
    "    return sorted(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort3(mylist):\n",
    "    mylist.sort()\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, set_up() has two parameters, both of which are modified inside the function. We begin by assigning an empty string to w and an empty dictionary to p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up(word, properties):\n",
    "    word = 'lolcat'\n",
    "    properties.append('noun')\n",
    "    properties = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ''\n",
    "p = []\n",
    "set_up(w, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ''\n",
    "word = w\n",
    "word = 'lolcat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties.append('noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheking Parameter Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python does not force us to declare the type of a variable when we write a program,and this permits us to define functions that are flexible about the type of their arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag([\"'Tis\", 'but','a', 'scratch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    assert isinstance(word, str), \"argument to tag() must be a string\"\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well-structured programs usually make extensive use of functions. When a block of program code grows longer than 10–20 lines, it is a great help to readability if the code is broken up into one or more functions, each one having a clear purpose. This is analogous to the way a good essay is divided into paragraphs, each expressing one main idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_corpus()\n",
    "# results = analyze(data)\n",
    "# present(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(url, freqdist, n):\n",
    "    html = requests.get(url).text\n",
    "    text = BeautifulSoup(html, 'lxml').get_text()\n",
    "    freqdist.update(\n",
    "        word.lower() \n",
    "        for word in nltk.word_tokenize(text)\n",
    "    )\n",
    "    print(freqdist.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "constitution = \"http://www.archives.gov/national-archives-experience/charters/constitution_transcript.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.probability.FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"''\", 374), (',', 189), (':1', 75), (':', 72), ('the', 71), ('{', 41), ('}', 41), (';', 40), ('of', 39), ('(', 28), (')', 28), (\"'\", 20), ('archives', 20), ('#', 20), ('and', 19), ('.', 16), ('[', 15), (']', 15), ('``', 15), ('national', 14)]\n"
     ]
    }
   ],
   "source": [
    "freq_words(constitution, fd, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(url):\n",
    "    html = requests.get(url).text\n",
    "    text = BeautifulSoup(html, 'lxml').get_text()\n",
    "    freqdist = nltk.FreqDist(\n",
    "        word.lower() \n",
    "        for word in nltk.word_tokenize(text)\n",
    "    )\n",
    "    return freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = freq_words(constitution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"''\", 374), (',', 189), (':1', 75), (':', 72), ('the', 71), ('{', 41), ('}', 41), (';', 40), ('of', 39), ('(', 28), (')', 28), (\"'\", 20), ('archives', 20), ('#', 20), ('and', 19), ('.', 16), ('[', 15), (']', 15), ('``', 15), ('national', 14)]\n"
     ]
    }
   ],
   "source": [
    "print(fd.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = nltk.word_tokenize(nltk.clean_url(constitution))\n",
    "# fd = nltk.FreqDist(word.lower() for word in words)\n",
    "# fd.keys()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have done a good job at decomposing our program into functions, then it should be easy to describe the purpose of each function in plain language, and provide this in the docstring at the top of the function definition. This statement should not explain how the functionality is implemented; in fact, it should be possible to reimplement the function using a different method without changing this statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items\n",
    "    \n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In partical, return the fraction of indexs\n",
    "    {0<i<=len(test)}such that C{test[i] == reference[i]}.\n",
    "    \n",
    "    >>> accuracy(['ADJ', 'N', 'V','N'], ['N', 'N','V','ADJ'])\n",
    "    0.5\n",
    "    \n",
    "    @param reference: An ordered list of reference values.\n",
    "    @type reference: C{list}\n",
    "    @param test: A list of values to compare against the corresponding\n",
    "    reference values.\n",
    "    @type test: C{list}\n",
    "    @rtype: C{float}\n",
    "    @raise ValueError: If C{reference} and C{length} do not have the\n",
    "    same length.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"List must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x,y in zip(reference, test):\n",
    "        if x==y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct)/len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(['ADJ', 'N', 'V','N'], ['N', 'N','V','ADJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Doing More with Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section discusses more advanced features, which you may prefer to skip on the first time through this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions As Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the', \n",
    "       'sounds', 'will','take', 'care', 'of', 'themselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_property(prop):\n",
    "    return [prop(word) for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(word):\n",
    "    return word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(last_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'Take',\n",
       " 'and',\n",
       " 'care',\n",
       " 'care',\n",
       " 'of',\n",
       " 'of',\n",
       " 'sense',\n",
       " 'sounds',\n",
       " 'take',\n",
       " 'the',\n",
       " 'the',\n",
       " 'themselves',\n",
       " 'will']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will',\n",
       " 'themselves',\n",
       " 'the',\n",
       " 'the',\n",
       " 'take',\n",
       " 'sounds',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'of',\n",
       " 'care',\n",
       " 'care',\n",
       " 'and',\n",
       " 'Take',\n",
       " ',']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'of',\n",
       " 'of',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Take',\n",
       " 'care',\n",
       " 'will',\n",
       " 'take',\n",
       " 'care',\n",
       " 'sense',\n",
       " 'sounds',\n",
       " 'themselves']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More efficient than via cmp_to_key\n",
    "sorted(sent, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'of',\n",
       " 'of',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Take',\n",
       " 'care',\n",
       " 'will',\n",
       " 'take',\n",
       " 'care',\n",
       " 'sense',\n",
       " 'sounds',\n",
       " 'themselves']"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import cmp_to_key\n",
    "\n",
    "sorted(sent, key=cmp_to_key(lambda x, y: len(x) - len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulative Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search1:\n",
      "Grizzlies'\n",
      "fizzled\n",
      "Rizzuto\n",
      "huzzahs\n",
      "dazzler\n",
      "jazz\n",
      "Pezza\n",
      "Pezza\n",
      "Pezza\n",
      "embezzling\n",
      "embezzlement\n",
      "pizza\n",
      "jazz\n",
      "Ozzie\n",
      "nozzle\n",
      "drizzly\n",
      "puzzle\n",
      "puzzle\n",
      "dazzling\n",
      "Sizzling\n",
      "guzzle\n",
      "puzzles\n",
      "dazzling\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "dizzy\n",
      "jazz\n",
      "Jazz\n",
      "puzzler\n",
      "jazz\n",
      "jazzmen\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "nozzles\n",
      "nozzle\n",
      "puzzle\n",
      "buzz\n",
      "puzzle\n",
      "blizzard\n",
      "blizzard\n",
      "sizzling\n",
      "puzzled\n",
      "puzzle\n",
      "puzzle\n",
      "muzzle\n",
      "muzzle\n",
      "muezzin\n",
      "blizzard\n",
      "Neo-Jazz\n",
      "jazz\n",
      "muzzle\n",
      "piazzas\n",
      "puzzles\n",
      "puzzles\n",
      "embezzle\n",
      "buzzed\n",
      "snazzy\n",
      "buzzes\n",
      "puzzled\n",
      "puzzled\n",
      "muzzle\n",
      "whizzing\n",
      "jazz\n",
      "Belshazzar\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie's\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "blizzard\n",
      "blizzards\n",
      "blizzard\n",
      "blizzard\n",
      "fuzzy\n",
      "Lazzeri\n",
      "Piazza\n",
      "piazza\n",
      "palazzi\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "Palazzo\n",
      "Palazzo\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "palazzo\n",
      "Palazzo\n",
      "Palazzo\n",
      "Piazza\n",
      "piazza\n",
      "piazza\n",
      "piazza\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "Piazza\n",
      "piazza\n",
      "pizza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "dazzling\n",
      "puzzling\n",
      "Wozzek\n",
      "dazzling\n",
      "dazzling\n",
      "buzzing\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Fuzzy\n",
      "Lizzy\n",
      "Lizzy\n",
      "jazz\n",
      "fuzzy\n",
      "puzzles\n",
      "puzzling\n",
      "puzzling\n",
      "dazzle\n",
      "puzzle\n",
      "dazzling\n",
      "puzzled\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazzy\n",
      "whizzed\n",
      "frazzled\n",
      "quizzical\n",
      "puzzling\n",
      "poetry-and-jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Dizzy\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "dazzled\n",
      "bedazzlement\n",
      "bedazzled\n",
      "Piazzo\n",
      "nozzles\n",
      "nozzles\n",
      "buzzing\n",
      "dazzles\n",
      "dizzy\n",
      "puzzling\n",
      "puzzling\n",
      "puzzling\n",
      "puzzle\n",
      "muzzle\n",
      "puzzled\n",
      "nozzle\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "puzzled\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "dazzling\n",
      "pizzicato\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "nozzle\n",
      "grizzled\n",
      "fuzzy\n",
      "muzzle\n",
      "puzzled\n",
      "puzzle\n",
      "muzzle\n",
      "blizzard\n",
      "buzz\n",
      "dizzily\n",
      "drizzle\n",
      "drizzle\n",
      "drizzle\n",
      "sizzled\n",
      "puzzled\n",
      "puzzled\n",
      "puzzled\n",
      "fuzzed\n",
      "buzz\n",
      "buzz\n",
      "buzz\n",
      "buzz-buzz-buzz\n",
      "buzzes\n",
      "fuzzy\n",
      "frizzled\n",
      "drizzle\n",
      "drizzle\n",
      "drizzling\n",
      "drizzling\n",
      "fuzz\n",
      "jazz\n",
      "jazz\n",
      "fuzz\n",
      "puzzle\n",
      "puzzling\n",
      "Nozze\n",
      "mezzo\n",
      "puzzled\n",
      "puzzled\n",
      "dazzling\n",
      "muzzle\n",
      "muzzle\n",
      "muzzle\n",
      "buzzed\n",
      "whizzed\n",
      "sizzled\n",
      "palazzos\n",
      "puzzlement\n",
      "frizzling\n",
      "puzzled\n",
      "puzzled\n",
      "puzzled\n",
      "dazzling\n",
      "muzzles\n",
      "fuzzy\n",
      "jazz\n",
      "ex-jazz\n",
      "sizzle\n",
      "grizzly\n",
      "guzzled\n",
      "buzzing\n",
      "fuzz\n",
      "nuzzled\n",
      "Kizzie\n",
      "Kizzie\n",
      "Kizzie\n",
      "Kezziah\n",
      "Kizzie\n",
      "Kizzie\n",
      "Buzz's\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "dizzy\n",
      "piazza\n",
      "buzzing\n",
      "Puzzled\n",
      "dizziness\n",
      "dazzled\n",
      "Piazza\n",
      "Carrozza\n",
      "fuzzy\n",
      "dizzy\n",
      "buzzing\n",
      "buzzing\n",
      "puzzled\n",
      "puzzling\n",
      "puzzled\n",
      "puzzled\n",
      "Quizzical\n",
      "pizza\n"
     ]
    }
   ],
   "source": [
    "print(\"search1:\")\n",
    "for item in search1('zz', nltk.corpus.brown.words()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search2:\n",
      "Grizzlies'\n",
      "fizzled\n",
      "Rizzuto\n",
      "huzzahs\n",
      "dazzler\n",
      "jazz\n",
      "Pezza\n",
      "Pezza\n",
      "Pezza\n",
      "embezzling\n",
      "embezzlement\n",
      "pizza\n",
      "jazz\n",
      "Ozzie\n",
      "nozzle\n",
      "drizzly\n",
      "puzzle\n",
      "puzzle\n",
      "dazzling\n",
      "Sizzling\n",
      "guzzle\n",
      "puzzles\n",
      "dazzling\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "dizzy\n",
      "jazz\n",
      "Jazz\n",
      "puzzler\n",
      "jazz\n",
      "jazzmen\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "nozzles\n",
      "nozzle\n",
      "puzzle\n",
      "buzz\n",
      "puzzle\n",
      "blizzard\n",
      "blizzard\n",
      "sizzling\n",
      "puzzled\n",
      "puzzle\n",
      "puzzle\n",
      "muzzle\n",
      "muzzle\n",
      "muezzin\n",
      "blizzard\n",
      "Neo-Jazz\n",
      "jazz\n",
      "muzzle\n",
      "piazzas\n",
      "puzzles\n",
      "puzzles\n",
      "embezzle\n",
      "buzzed\n",
      "snazzy\n",
      "buzzes\n",
      "puzzled\n",
      "puzzled\n",
      "muzzle\n",
      "whizzing\n",
      "jazz\n",
      "Belshazzar\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie's\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "Lizzie\n",
      "blizzard\n",
      "blizzards\n",
      "blizzard\n",
      "blizzard\n",
      "fuzzy\n",
      "Lazzeri\n",
      "Piazza\n",
      "piazza\n",
      "palazzi\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "Palazzo\n",
      "Palazzo\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "palazzo\n",
      "Palazzo\n",
      "Palazzo\n",
      "Piazza\n",
      "piazza\n",
      "piazza\n",
      "piazza\n",
      "Piazza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "Piazza\n",
      "piazza\n",
      "pizza\n",
      "Piazza\n",
      "Palazzo\n",
      "palazzo\n",
      "dazzling\n",
      "puzzling\n",
      "Wozzek\n",
      "dazzling\n",
      "dazzling\n",
      "buzzing\n",
      "Jazz\n",
      "jazz\n",
      "Jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Fuzzy\n",
      "Lizzy\n",
      "Lizzy\n",
      "jazz\n",
      "fuzzy\n",
      "puzzles\n",
      "puzzling\n",
      "puzzling\n",
      "dazzle\n",
      "puzzle\n",
      "dazzling\n",
      "puzzled\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazzy\n",
      "whizzed\n",
      "frazzled\n",
      "quizzical\n",
      "puzzling\n",
      "poetry-and-jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "Dizzy\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "poetry-and-jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "dazzled\n",
      "bedazzlement\n",
      "bedazzled\n",
      "Piazzo\n",
      "nozzles\n",
      "nozzles\n",
      "buzzing\n",
      "dazzles\n",
      "dizzy\n",
      "puzzling\n",
      "puzzling\n",
      "puzzling\n",
      "puzzle\n",
      "muzzle\n",
      "puzzled\n",
      "nozzle\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "puzzled\n",
      "Pozzatti\n",
      "Pozzatti\n",
      "dazzling\n",
      "pizzicato\n",
      "Jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "jazz\n",
      "nozzle\n",
      "grizzled\n",
      "fuzzy\n",
      "muzzle\n",
      "puzzled\n",
      "puzzle\n",
      "muzzle\n",
      "blizzard\n",
      "buzz\n",
      "dizzily\n",
      "drizzle\n",
      "drizzle\n",
      "drizzle\n",
      "sizzled\n",
      "puzzled\n",
      "puzzled\n",
      "puzzled\n",
      "fuzzed\n",
      "buzz\n",
      "buzz\n",
      "buzz\n",
      "buzz-buzz-buzz\n",
      "buzzes\n",
      "fuzzy\n",
      "frizzled\n",
      "drizzle\n",
      "drizzle\n",
      "drizzling\n",
      "drizzling\n",
      "fuzz\n",
      "jazz\n",
      "jazz\n",
      "fuzz\n",
      "puzzle\n",
      "puzzling\n",
      "Nozze\n",
      "mezzo\n",
      "puzzled\n",
      "puzzled\n",
      "dazzling\n",
      "muzzle\n",
      "muzzle\n",
      "muzzle\n",
      "buzzed\n",
      "whizzed\n",
      "sizzled\n",
      "palazzos\n",
      "puzzlement\n",
      "frizzling\n",
      "puzzled\n",
      "puzzled\n",
      "puzzled\n",
      "dazzling\n",
      "muzzles\n",
      "fuzzy\n",
      "jazz\n",
      "ex-jazz\n",
      "sizzle\n",
      "grizzly\n",
      "guzzled\n",
      "buzzing\n",
      "fuzz\n",
      "nuzzled\n",
      "Kizzie\n",
      "Kizzie\n",
      "Kizzie\n",
      "Kezziah\n",
      "Kizzie\n",
      "Kizzie\n",
      "Buzz's\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "Buzz\n",
      "dizzy\n",
      "piazza\n",
      "buzzing\n",
      "Puzzled\n",
      "dizziness\n",
      "dazzled\n",
      "Piazza\n",
      "Carrozza\n",
      "fuzzy\n",
      "dizzy\n",
      "buzzing\n",
      "buzzing\n",
      "puzzled\n",
      "puzzling\n",
      "puzzled\n",
      "puzzled\n",
      "Quizzical\n",
      "pizza\n"
     ]
    }
   ],
   "source": [
    "print(\"search2:\")\n",
    "for item in search2('zz', nltk.corpus.brown.words()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "    else:\n",
    "        for perm in permutations(seq[1:]):\n",
    "            for i in range(len(perm)+1):\n",
    "                yield perm[:i] + seq[0:1] + perm[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(permutations(['police', 'fish', 'buffalo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-Order Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions start by initializing some storage, and iterate over input to build it up,before returning some final object (a large structure or aggregated result). A standard way to do this is to initialize an empty list, accumulate the material, then return the list, as shown in function search1() in next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_word(word):\n",
    "    return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "        'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = list(map(len, nltk.corpus.brown.sents(categories='news')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(w) for w in nltk.corpus.brown.sents(categories='news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 3, 0]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda w: len(list(filter(lambda c: c.lower() in \"aeiou\", w))), sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 3, 0]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len([c for c in w if c.lower() in \"aeiou\"]) for w in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are a lot of parameters it is easy to get confused about the correct order. Instead we can refer to parameters by name, and even assign them a default value just in case one was not provided by the calling program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(msg='<empty>', num=1):\n",
    "    return msg * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<empty><empty><empty>'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AliceAliceAliceAliceAlice'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=5, msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "generic(1, \"African swallow\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = [['four', 'calling', 'birds'],\n",
    "        ['three', 'French', 'hens'],\n",
    "        ['two', 'turtle', 'doves']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(song[0], song[1], song[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10):\n",
    "    text = open(file).read()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    freqdist = FreqDist(t for t in tokens if len(t) >= min)\n",
    "    return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = freq_words(gutenberg.abspath('carroll-alice.txt'), 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = freq_words(gutenberg.abspath('carroll-alice.txt'), min=4, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = freq_words(gutenberg.abspath('carroll-alice.txt'), num=10, min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10, trace=False):\n",
    "    freqdist = FreqDist()\n",
    "    if trace: print(\"Opening\", file)\n",
    "    text = open(file).read()\n",
    "    if trace: print(\"Read in %d characters\" % len(text))\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if len(word) >= min:\n",
    "            freqdist[word] += 1\n",
    "            if trace and freqdist.N() % 100 == 0: print(\".\")\n",
    "    if trace: print()\n",
    "    return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening C:\\Users\\JafarauR\\AppData\\Roaming\\nltk_data\\corpora\\gutenberg\\carroll-alice.txt\n",
      "Read in 144395 characters\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fw = freq_words(gutenberg.abspath('carroll-alice.txt'), num=10, min=4, trace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming is a skill that is acquired over several years of experience with a variety of programming languages and tasks. Key high-level abilities are algorithm design and its manifestation in structured programming. Key low-level abilities include familiarity with the syntactic constructs of the language, and knowledge of a variety of diagnostic methods for trouble-shooting a program which does not exhibit the expected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mastery of programming depends on having a variety of problem-solving skills to draw\n",
    "upon when the program doesn’t work as expected. Something as trivial as a misplaced\n",
    "symbol might cause the program to behave very differently. We call these “bugs” because\n",
    "they are tiny in comparison to the damage they can cause. They creep into our\n",
    "code unnoticed, and it’s only much later when we’re running the program on some\n",
    "new data that their presence is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_words(text, wordlength, result=[]):\n",
    "    for word in text:\n",
    "    if len(word) == wordlength:\n",
    "    result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 2, ['ur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most code errors result from the programmer making incorrect assumptions, the first thing to do when you detect a bug is to check your assumptions. Localize the problem by adding print statements to the program, showing the value of important variables,and showing how far the program has progressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mymodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdb.run('mymodule.myfunction()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_words(['cat'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdb.run(\"find_words(['dog'], 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section discusses more advanced concepts, which you may prefer to skip on the first time through this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorial1(n):\n",
    "    result = 1\n",
    "    for i in range(n):\n",
    "        result *= (i+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorial2(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial2(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size1(s):\n",
    "    return 1 + sum(size1(child) for child in s.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size2(s):\n",
    "    layer = [s]\n",
    "    total = 0\n",
    "    while layer:\n",
    "        total += len(layer)\n",
    "        layer = [h for c in layer for h in c.hyponyms()]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size1(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size2(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie = nltk.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert(trie, 'chat', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert(trie, 'chien', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert(trie, 'chair', 'flesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert(trie, 'chic', 'stylish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie = dict(trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space-Time Trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sometimes significantly speed up the execution of a program by building an auxiliary data structure, such as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw(file):\n",
    "    contents = open(file).read()\n",
    "    contents = re.sub(r'<.*?>', ' ', contents)\n",
    "    contents = re.sub('\\s+', ' ', contents)\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def snippet(doc, term): # buggy\n",
    "    text = ' '*30 + raw(doc) + ' '*30\n",
    "    pos = text.index(term)\n",
    "    return text[pos-30:pos+30]\n",
    "print \"Building Index...\"\n",
    "files = nltk.corpus.movie_reviews.abspaths()\n",
    "idx = nltk.Index((w, f) for f in files for w in raw(f).split())\n",
    "query = ''\n",
    "while query != \"quit\":\n",
    "    query = raw_input(\"query> \")\n",
    "    if query in idx:\n",
    "        for doc in idx[query]:\n",
    "                print snippet(doc, query)\n",
    "    else:\n",
    "        print \"Not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tagged_corpus):\n",
    "    words = set()\n",
    "    tags = set()\n",
    "    for sent in tagged_corpus:\n",
    "        for word, tag in sent:\n",
    "        words.add(word)\n",
    "        tags.add(tag)\n",
    "    wm = dict((w,i) for (i,w) in enumerate(words))\n",
    "    tm = dict((t,i) for (i,t) in enumerate(tags))\n",
    "    return [[(wm[w], tm[t]) for (w,t) in sent] for sent in tagged_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_list = \"import random; vocab = range(%d)\" % vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_set = \"import random; vocab = set(range(%d))\" % vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statement = \"random.randint(0, %d) in vocab\" % vocab_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print Timer(statement, setup_list).timeit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print Timer(statement, setup_set).timeit(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic programming is a general technique for designing algorithms which is widely used in natural language processing. The term “programming” is used in a different sense to what you might expect, to mean planning or scheduling. Dynamic programming is used when a problem contains overlapping subproblems. Instead of computing solutions to these subproblems repeatedly, we simply store them in a lookup table. In the remainder of this section, we will introduce dynamic programming, but in a rather different context to syntactic parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def virahanka1(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka1(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka1(n-2)]\n",
    "        return s + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def virahanka2(n):\n",
    "    lookup = [[\"\"], [\"S\"]]\n",
    "    for i in range(n-1):\n",
    "        s = [\"S\" + prosody for prosody in lookup[i+1]]\n",
    "        l = [\"L\" + prosody for prosody in lookup[i]]\n",
    "        lookup.append(s + l)\n",
    "    return lookup[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def virahanka3(n, lookup={0:[\"\"], 1:[\"S\"]}):\n",
    "    if n not in lookup:\n",
    "        s = [\"S\" + prosody for prosody in virahanka3(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka3(n-2)]\n",
    "        lookup[n] = s + l\n",
    "    return lookup[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import memoize\n",
    "@memoize\n",
    "def virahanka4(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka4(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka4(n-2)]\n",
    "        return s + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virahanka1(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virahanka2(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virahanka3(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virahanka4(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Sample of Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has hundreds of third-party libraries, specialized software packages that extend the functionality of Python. NLTK is one such library. To realize the full power of Python programming, you should become familiar with several other libraries. Most of these will need to be manually installed on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has some libraries that are useful for visualizing language data. The Matplotlib package supports sophisticated plotting functions with a MATLAB-style interface, and is available from http://matplotlib.sourceforge.net/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = 'rgbcmyk' # red, green, blue, cyan, magenta, yellow, black\n",
    "def bar_chart(categories, words, counts):\n",
    "    \"Plot a bar chart showing counts for each word by category\"\n",
    "    import pylab\n",
    "    ind = pylab.arange(len(words))\n",
    "    width = 1 / (len(categories) + 1)\n",
    "    bar_groups = []\n",
    "    for c in range(len(categories)):\n",
    "        bars = pylab.bar(ind+c*width, counts[categories[c]], width,\n",
    "                         color=colors[c % len(colors)])\n",
    "        bar_groups.append(bars)\n",
    "    pylab.xticks(ind+width, words)\n",
    "    pylab.legend([b[0] for b in bar_groups], categories, loc='upper left')\n",
    "    pylab.ylabel('Frequency')\n",
    "    pylab.title('Frequency of Six Modal Verbs by Genre')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres = ['news', 'religion', 'hobbies', 'government', 'adventure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfdist = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in genres\n",
    "    for word in nltk.corpus.brown.words(categories=genre)\n",
    "    if word in modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for genre in genres:\n",
    "    counts[genre] = [cfdist[genre][word] for word in modals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bar_chart(genres, modals, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.savefig('modals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Content-Type: text/html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '<html><body>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '<img src=\"modals.png\"/>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '</body></html>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NetworkX package is for defining and manipulating structures consisting of nodes and edges, known as graphs. It is available from https://networkx.lanl.gov/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse(graph, start, node):\n",
    "    graph.depth[node.name] = node.shortest_path_distance(start)\n",
    "    for child in node.hyponyms():\n",
    "        graph.add_edge(node.name, child.name)\n",
    "        traverse(graph, start, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyponym_graph(start):\n",
    "    G = nx.Graph()\n",
    "    G.depth = {}\n",
    "    traverse(G, start, start)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_draw(graph):\n",
    "    nx.draw_graphviz(graph,\n",
    "        node_size = [16 * graph.degree(n) for n in graph],\n",
    "        node_color = [graph.depth[n] for n in graph],\n",
    "        with_labels = False)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = hyponym_graph(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_draw(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language analysis work often involves data tabulations, containing information about lexical items, the participants in an empirical study, or the linguistic features extracted from a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = open(\"lexicon.csv\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in csv.reader(input_file):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy package provides substantial support for numerical processing in Python. NumPy has a multidimensional array object, which is easy to initialize and access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cube = array([ [[0,0,0], [1,1,1], [2,2,2]],\n",
    "              [[3,3,3], [4,4,4], [5,5,5]],\n",
    "              [[6,6,6], [7,7,7], [8,8,8]] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cube[1,1,1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
