{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a string s = 'colorless'. Write a Python statement that changes this to\n",
    "“colourless” using only the slice and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'colorless'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:4] + 'u' + s[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the slice notation to remove morphological endings on words. For\n",
    "example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice\n",
    "notation to remove the affixes from these words (we’ve inserted a hyphen to indicate\n",
    "the affix boundary, but omit this from your strings): dish-es, run-ning, nationality,\n",
    "un-do, pre-heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dish-es'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'dishes'\n",
    "w[:-2] + '-' + w[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run-ning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'running'\n",
    "w[:3] + '-'  + w[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nation-ality'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'nationality'\n",
    "w[:6] + '-' + w[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un-do'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'undo'\n",
    "w[:2] + '-' + w[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre-heat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'preheat'\n",
    "w[:3] + '-' + w[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how we can generate an IndexError by indexing beyond the end of a\n",
    "string. Is it possible to construct an index that goes too far to the left, before the\n",
    "start of the string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 c\n",
      "2 b\n",
      "3 a\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5e12b44396f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'abc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# w[0], w[-1], w[-2], w[-3], w[-4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "w = 'abc'\n",
    "for i in range(len(w) + 2):\n",
    "    print(i, w[-i])\n",
    "# w[0], w[-1], w[-2], w[-3], w[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, no. The minimum index value is -len(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a “step” size for the slice. The following returns every second\n",
    "character within the slice: monty[6:11:2]. It also works in the reverse direction:\n",
    "monty[10:5:-2]. Try these for yourself, and then experiment with different step\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'Hello world!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[2:9:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[-1:0:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you ask the interpreter to evaluate monty[::-1]? Explain why\n",
    "this is a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse string. Moving from the start to end of the string with the negative step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the class of strings matched by the following regular expressions:<div>\n",
    "a. [a-zA-Z]+<div>\n",
    "b. [A-Z][a-z]*<div>\n",
    "c. p[aeiou]{,2}t<div>\n",
    "d. \\d+(\\.\\d+)?<div>\n",
    "e. ([^aeiou][aeiou][^aeiou])*<div>\n",
    "f. \\w+|[^\\w\\s]+<div>\n",
    "Test your answers using nltk.re_show()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. any combination of one or more letters in lower/upper case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. any pair of letters, where the first letter is in upper case and the second is in lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. any 3-4-letter word that starts with 'p', ends with 't', and contains inside 1-2 vowels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. any number (may have leading zeroes), that has or hasn't a floating part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. 3-char combinations that starts with non-vowel chars followed by vowel char, and ends with non-vowwel char again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. any alphanumeric sequence or any sequence that doesn't contain alphanumeric or space chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write regular expressions to match the following classes of strings:<div>\n",
    "a. A single determiner (assume that a, an, and the are the only determiners)<div>\n",
    "b. An arithmetic expression using integers, addition, and multiplication, such as 2*3+8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.re_show(\n",
    "    regexp='\\\\b([aA]|[aA]n|[tT]he)\\\\b',\n",
    "    string='A single determiner (assume that a, an, and the are the only determiners)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.re_show(\n",
    "    regexp='\\d([*+]\\d)+',\n",
    "    string='An arithmetic expression using integers, addition, and multiplication, such as 2*3+8'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a utility function that takes a URL as its argument, and returns the contents\n",
    "of the URL, with all HTML markup removed. Use urllib.urlopen to access the contents of the URL, e.g.:\n",
    "raw_contents = urllib.urlopen('http://www.nltk.org/').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('http://www.nltk.org/').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9 (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save some text into a file corpus.txt. Define a function load(f) that reads from\n",
    "the file named in its sole argument, and returns a string containing the text of the\n",
    "file.<div>\n",
    "a. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the various\n",
    "kinds of punctuation in this text. Use one multiline regular expression inline\n",
    "comments, using the verbose flag (?x).<div>\n",
    "b. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the following\n",
    "kinds of expressions: monetary amounts; dates; names of people and\n",
    "organizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite the following loop as a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "result = []\n",
    "for word in sent:\n",
    "    word_len = (word, len(word))\n",
    "    result.append(word_len)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [(w, len(w)) for w in sent]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a string raw containing a sentence of your own choosing. Now, split raw\n",
    "on some character other than space, such as 's'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"Define a string raw containing a sentence of your own choosing. Now, split raw\n",
    "on some character other than space, such as 's'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Define a ',\n",
       " 'tring raw containing a ',\n",
       " 'entence of your own choo',\n",
       " 'ing. Now, ',\n",
       " 'plit raw\\non ',\n",
       " 'ome character other than ',\n",
       " 'pace, ',\n",
       " 'uch a',\n",
       " \" '\",\n",
       " \"'\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.split('s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a for loop to print out the characters of a string, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "e\n",
      "f\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "w\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "y\n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "c\n",
      "h\n",
      "o\n",
      "o\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "N\n",
      "o\n",
      "w\n",
      ",\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "i\n",
      "t\n",
      " \n",
      "r\n",
      "a\n",
      "w\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "'\n",
      "s\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "for c in raw:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between calling split on a string with no argument and\n",
    "one with ' ' as the argument, e.g., sent.split() versus sent.split(' ')? What\n",
    "happens when the string being split contains tab characters, consecutive space\n",
    "characters, or a sequence of tabs and spaces? (In IDLE you will need to use '\\t' to\n",
    "enter a tab character.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If sep is not specified or is None, any whitespace string (\\s) is a separator and empty strings are removed from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd', 'sad', 'asdasds']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'asd sad\\n\\t\\t\\t\\t\\r   asdasds'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd', 'sad\\n\\t\\t\\t\\t\\r', '', '', 'asdasds']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'asd sad\\n\\t\\t\\t\\t\\r   asdasds'.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable words containing a list of words. Experiment with\n",
    "words.sort() and sorted(words). What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Create', 'a', 'variable', 'words', 'containing', 'a', 'list', 'of', 'words']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize('Create a variable words containing a list of words')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Create', 'a', 'a', 'containing', 'list', 'of', 'variable', 'words', 'words']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sort()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Create', 'a', 'a', 'containing', 'list', 'of', 'variable', 'words', 'words']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to https://stackoverflow.com/questions/22442378/what-is-the-difference-between-sortedlist-vs-list-sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>sorted() returns a new sorted list</b>, leaving the original list unaffected. <b>list.sort() sorts the list in-place</b>, mutating the list indices, and returns None (like all in-place operations).\n",
    "\n",
    "sorted() works on any iterable, not just lists. Strings, tuples, dictionaries (you'll get the keys), generators, etc., returning a list containing all elements, sorted.\n",
    "\n",
    "Use list.sort() when you want to mutate the list, sorted() when you want a new sorted object back. Use sorted() when you want to sort something that is an iterable, not a list yet.\n",
    "\n",
    "For lists, <b>list.sort() is faster than sorted()</b> because it doesn't have to create a copy. For any other iterable, you have no choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the difference between strings and integers by typing the following at a\n",
    "Python prompt: \"3\" * 7 and 3 * 7. Try converting between strings and integers\n",
    "using int(\"3\") and str(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3333333', 21)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"3\" * 7,  3 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, '3')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"3\"),  str(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 16 (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we asked you to use a text editor to create a file called test.py, containing the single line monty = 'Monty Python'. If you haven’t already done this (or can’t find the file), go ahead and do it now. Next, start up a new session with the Python interpreter, and enter the expression monty at the prompt. You will get an error from the interpreter. Now, try the following (note that you have to leave off the .py part of the filename):<div>\n",
    "<b>from test import msg</b><div>\n",
    "<b>msg</b><div>\n",
    "This time, Python should return with a value. You can also try import test, in which case Python should be able to evaluate the expression test.monty at the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when the formatting strings %6s and %-6s are used to display\n",
    "strings that are longer than six characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aaaaaaa', '    bb')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%6s' % 'aaaaaaa', '%6s' % 'bb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bbbbbbb', 'bb    ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%-6s' % 'bbbbbbb', '%-6s' % 'bb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 18 (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in some text from a corpus, tokenize it, and print the list of all wh-word\n",
    "types that occur. (wh-words in English are used in questions, relative clauses, and\n",
    "exclamations: who, which, what, and so on.) Print them in order. Are any words\n",
    "duplicated in this list, because of the presence of case distinctions or punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = gutenberg.raw('carroll-alice.txt')\n",
    "words = nltk.word_tokenize(raw_text)\n",
    "words = [w.lower() for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_word_types = sorted(set(w for w in words if w.startswith('wh')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'where',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whiles',\n",
       " 'whiskers',\n",
       " 'whisper',\n",
       " 'whispered',\n",
       " 'whispers',\n",
       " 'whistle',\n",
       " 'whistling',\n",
       " 'white',\n",
       " 'whiting',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_word_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file consisting of words and (made up) frequencies, where each line\n",
    "consists of a word, the space character, and a positive integer, e.g., fuzzy 53. Read\n",
    "the file into a Python list using open(filename).readlines(). Next, break each line\n",
    "into its two fields using split(), and convert the number into an integer using\n",
    "int(). The result should be a list of the form: [['fuzzy', 53], ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['x', 53], ['y', 156], ['z', 567]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "with open('ch3_ex19.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        w, freq = line.split()\n",
    "        result.append([w, int(freq)])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to access a favorite web page and extract some text from it. For\n",
    "example, access a weather site and extract the forecast top temperature for your\n",
    "town or city today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.tut.by/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$2.0433'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_rate = (\n",
    "    content\n",
    "    .select_one('a[href=\"https://finance.tut.by/kurs/\"]')\n",
    "    .get_text(strip=True)\n",
    ")\n",
    "dollar_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function unknown() that takes a URL as its argument, and returns a list\n",
    "of unknown words that occur on that web page. In order to do this, extract all\n",
    "substrings consisting of lowercase letters (using re.findall()) and remove any\n",
    "items from this set that occur in the Words Corpus (nltk.corpus.words). Try to\n",
    "categorize these words manually and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown(url, regex='[a-z]+'):\n",
    "    response = requests.get(url)\n",
    "    text = BeautifulSoup(response.text, \"lxml\").get_text()\n",
    "    words_set = set(words.words())\n",
    "    return sorted(set([\n",
    "        s for s in re.findall(regex, text) \n",
    "        if s not in words_set\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words = unknown(\"https://en.wikipedia.org/wiki/Plain_text\")\n",
    "len(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abel',\n",
       " 'ac',\n",
       " 'accented',\n",
       " 'acintosh',\n",
       " 'ackend',\n",
       " 'adding',\n",
       " 'adges',\n",
       " 'adget',\n",
       " 'ahasa',\n",
       " 'ain',\n",
       " 'ais',\n",
       " 'allbacks',\n",
       " 'allocated',\n",
       " 'allows',\n",
       " 'ames',\n",
       " 'amespace',\n",
       " 'amespaces',\n",
       " 'andom',\n",
       " 'anguage',\n",
       " 'anguages',\n",
       " 'anonical',\n",
       " 'anuary',\n",
       " 'applications',\n",
       " 'arametric',\n",
       " 'arget',\n",
       " 'argued',\n",
       " 'ariant',\n",
       " 'ariants',\n",
       " 'arkup',\n",
       " 'articles',\n",
       " 'assigning',\n",
       " 'assigns',\n",
       " 'ata',\n",
       " 'atal',\n",
       " 'ategories',\n",
       " 'atin',\n",
       " 'ational',\n",
       " 'autostart',\n",
       " 'av',\n",
       " 'avoided',\n",
       " 'became',\n",
       " 'bfloat',\n",
       " 'bi',\n",
       " 'bignum',\n",
       " 'bitmapped',\n",
       " 'bits',\n",
       " 'bject',\n",
       " 'books',\n",
       " 'breaks',\n",
       " 'browsers',\n",
       " 'bstract',\n",
       " 'bytes',\n",
       " 'cachereport',\n",
       " 'categories',\n",
       " 'ccording',\n",
       " 'centralauth',\n",
       " 'centralautologin',\n",
       " 'challenged',\n",
       " 'changes',\n",
       " 'characters',\n",
       " 'charinsert',\n",
       " 'charset',\n",
       " 'checksum',\n",
       " 'chema',\n",
       " 'citations',\n",
       " 'cleartext',\n",
       " 'codes',\n",
       " 'commands',\n",
       " 'compactlinks',\n",
       " 'companies',\n",
       " 'completed',\n",
       " 'computers',\n",
       " 'computing',\n",
       " 'concerns',\n",
       " 'config',\n",
       " 'conflicts',\n",
       " 'considers',\n",
       " 'consisting',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'conventions',\n",
       " 'countries',\n",
       " 'covers',\n",
       " 'cputime',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'cs',\n",
       " 'csrf',\n",
       " 'ct',\n",
       " 'ction',\n",
       " 'ctober',\n",
       " 'ctuple',\n",
       " 'dashes',\n",
       " 'ddress',\n",
       " 'defines',\n",
       " 'desktop',\n",
       " 'developed',\n",
       " 'devices',\n",
       " 'died',\n",
       " 'digits',\n",
       " 'dingbats',\n",
       " 'disambiguation',\n",
       " 'ditable',\n",
       " 'ditor',\n",
       " 'dmy',\n",
       " 'documents',\n",
       " 'doesn',\n",
       " 'doi',\n",
       " 'drawings',\n",
       " 'ead',\n",
       " 'earch',\n",
       " 'eatured',\n",
       " 'eb',\n",
       " 'ebruary',\n",
       " 'ec',\n",
       " 'ecember',\n",
       " 'ecent',\n",
       " 'ecimal',\n",
       " 'ecord',\n",
       " 'ecursive',\n",
       " 'ederlands',\n",
       " 'edia',\n",
       " 'edirect',\n",
       " 'edited',\n",
       " 'editors',\n",
       " 'educed',\n",
       " 'ee',\n",
       " 'efault',\n",
       " 'eference',\n",
       " 'eferences',\n",
       " 'efforts',\n",
       " 'efimprove',\n",
       " 'efinement',\n",
       " 'eflist',\n",
       " 'efore',\n",
       " 'elatedtopics',\n",
       " 'elayu',\n",
       " 'elevant',\n",
       " 'elp',\n",
       " 'email',\n",
       " 'emaphore',\n",
       " 'emoji',\n",
       " 'emplate',\n",
       " 'enables',\n",
       " 'encoded',\n",
       " 'encoding',\n",
       " 'encodings',\n",
       " 'endianness',\n",
       " 'enear',\n",
       " 'eneral',\n",
       " 'eneric',\n",
       " 'enhancements',\n",
       " 'entityaccesscount',\n",
       " 'entral',\n",
       " 'ep',\n",
       " 'eparator',\n",
       " 'ependent',\n",
       " 'eport',\n",
       " 'eptember',\n",
       " 'equest',\n",
       " 'erhaps',\n",
       " 'erman',\n",
       " 'ermanent',\n",
       " 'erms',\n",
       " 'ersonal',\n",
       " 'escriptions',\n",
       " 'esponse',\n",
       " 'estriction',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'etrieved',\n",
       " 'eutsch',\n",
       " 'evelopers',\n",
       " 'events',\n",
       " 'evision',\n",
       " 'expansiondepth',\n",
       " 'expensivefunctioncount',\n",
       " 'ext',\n",
       " 'failed',\n",
       " 'figuring',\n",
       " 'files',\n",
       " 'fonts',\n",
       " 'formats',\n",
       " 'formatted',\n",
       " 'formatting',\n",
       " 'forms',\n",
       " 'fter',\n",
       " 'googpub',\n",
       " 'hapter',\n",
       " 'haracter',\n",
       " 'has',\n",
       " 'hese',\n",
       " 'homas',\n",
       " 'homisticus',\n",
       " 'hor',\n",
       " 'hort',\n",
       " 'html',\n",
       " 'http',\n",
       " 'https',\n",
       " 'humans',\n",
       " 'hus',\n",
       " 'hypertext',\n",
       " 'hyphens',\n",
       " 'icense',\n",
       " 'idden',\n",
       " 'identified',\n",
       " 'ideographs',\n",
       " 'iew',\n",
       " 'iewer',\n",
       " 'iews',\n",
       " 'igit',\n",
       " 'ignoring',\n",
       " 'ikibase',\n",
       " 'ikidata',\n",
       " 'ikimedia',\n",
       " 'ikipedia',\n",
       " 'ikisource',\n",
       " 'iles',\n",
       " 'images',\n",
       " 'ime',\n",
       " 'iming',\n",
       " 'imple',\n",
       " 'inary',\n",
       " 'including',\n",
       " 'incompatibilities',\n",
       " 'ind',\n",
       " 'individuals',\n",
       " 'indows',\n",
       " 'ine',\n",
       " 'inifloat',\n",
       " 'init',\n",
       " 'instructions',\n",
       " 'integers',\n",
       " 'interpreted',\n",
       " 'ir',\n",
       " 'isclaimers',\n",
       " 'isplay',\n",
       " 'isual',\n",
       " 'itation',\n",
       " 'ite',\n",
       " 'ith',\n",
       " 'itle',\n",
       " 'ix',\n",
       " 'ixed',\n",
       " 'ixon',\n",
       " 'js',\n",
       " 'json',\n",
       " 'keying',\n",
       " 'laintext',\n",
       " 'languages',\n",
       " 'lement',\n",
       " 'letters',\n",
       " 'lgebraic',\n",
       " 'ligatures',\n",
       " 'limitreport',\n",
       " 'll',\n",
       " 'llen',\n",
       " 'loating',\n",
       " 'logo',\n",
       " 'loosest',\n",
       " 'lthough',\n",
       " 'ltr',\n",
       " 'machines',\n",
       " 'mainspace',\n",
       " 'matters',\n",
       " 'mbox',\n",
       " 'mediawiki',\n",
       " 'memusage',\n",
       " 'metaclass',\n",
       " 'metaobject',\n",
       " 'mmv',\n",
       " 'mw',\n",
       " 'nabled',\n",
       " 'nc',\n",
       " 'ncoding',\n",
       " 'ndex',\n",
       " 'ndianness',\n",
       " 'ndonesia',\n",
       " 'ndrew',\n",
       " 'nductive',\n",
       " 'needed',\n",
       " 'newline',\n",
       " 'newspapers',\n",
       " 'ng',\n",
       " 'ngland',\n",
       " 'nglish',\n",
       " 'nicode',\n",
       " 'nimals',\n",
       " 'ninterpreted',\n",
       " 'nion',\n",
       " 'nojs',\n",
       " 'nomin',\n",
       " 'noscript',\n",
       " 'nsourced',\n",
       " 'nteger',\n",
       " 'nteraction',\n",
       " 'nternational',\n",
       " 'nterval',\n",
       " 'ntity',\n",
       " 'numbers',\n",
       " 'numerated',\n",
       " 'oader',\n",
       " 'oberto',\n",
       " 'obile',\n",
       " 'objects',\n",
       " 'odified',\n",
       " 'og',\n",
       " 'ogging',\n",
       " 'oid',\n",
       " 'ointer',\n",
       " 'oken',\n",
       " 'ol',\n",
       " 'oldid',\n",
       " 'olicy',\n",
       " 'ollection',\n",
       " 'omain',\n",
       " 'oman',\n",
       " 'ommons',\n",
       " 'ommunications',\n",
       " 'ommunity',\n",
       " 'omplex',\n",
       " 'omposite',\n",
       " 'omputers',\n",
       " 'onate',\n",
       " 'ones',\n",
       " 'onflicts',\n",
       " 'ong',\n",
       " 'onsortium',\n",
       " 'ontact',\n",
       " 'ontent',\n",
       " 'ontents',\n",
       " 'onth',\n",
       " 'ontributions',\n",
       " 'ontributors',\n",
       " 'ontrol',\n",
       " 'ookie',\n",
       " 'oolbar',\n",
       " 'oolean',\n",
       " 'ools',\n",
       " 'ooltips',\n",
       " 'oombs',\n",
       " 'op',\n",
       " 'opened',\n",
       " 'opted',\n",
       " 'options',\n",
       " 'opup',\n",
       " 'opups',\n",
       " 'ord',\n",
       " 'org',\n",
       " 'organisations',\n",
       " 'ormat',\n",
       " 'orpus',\n",
       " 'orsk',\n",
       " 'ortugu',\n",
       " 'ost',\n",
       " 'ostname',\n",
       " 'ot',\n",
       " 'others',\n",
       " 'otice',\n",
       " 'ottom',\n",
       " 'ouble',\n",
       " 'oundation',\n",
       " 'ource',\n",
       " 'ov',\n",
       " 'ove',\n",
       " 'ovember',\n",
       " 'owered',\n",
       " 'ownload',\n",
       " 'oyal',\n",
       " 'pages',\n",
       " 'panish',\n",
       " 'paque',\n",
       " 'paragraphs',\n",
       " 'parts',\n",
       " 'pecial',\n",
       " 'permitting',\n",
       " 'php',\n",
       " 'pload',\n",
       " 'png',\n",
       " 'popups',\n",
       " 'portions',\n",
       " 'positions',\n",
       " 'postexpandincludesize',\n",
       " 'ppgeneratednodes',\n",
       " 'ppvisitednodes',\n",
       " 'pr',\n",
       " 'pril',\n",
       " 'printers',\n",
       " 'problems',\n",
       " 'processing',\n",
       " 'programming',\n",
       " 'programs',\n",
       " 'projects',\n",
       " 'properties',\n",
       " 'ption',\n",
       " 'px',\n",
       " 'quicksurveys',\n",
       " 'quotes',\n",
       " 'ragmatic',\n",
       " 'rames',\n",
       " 'ransform',\n",
       " 'rbitrary',\n",
       " 'readers',\n",
       " 'reassigning',\n",
       " 'reate',\n",
       " 'reative',\n",
       " 'references',\n",
       " 'remaining',\n",
       " 'rench',\n",
       " 'representations',\n",
       " 'represented',\n",
       " 'reserves',\n",
       " 'reviews',\n",
       " 'rganisation',\n",
       " 'rganization',\n",
       " 'rimitive',\n",
       " 'rint',\n",
       " 'rintable',\n",
       " 'rivacy',\n",
       " 'robably',\n",
       " 'roduct',\n",
       " 'rogrammer',\n",
       " 'roject',\n",
       " 'rom',\n",
       " 'rooks',\n",
       " 'rotocol',\n",
       " 'roups',\n",
       " 'rown',\n",
       " 'rowser',\n",
       " 'rray',\n",
       " 'rticle',\n",
       " 'rticles',\n",
       " 'rules',\n",
       " 'ryte',\n",
       " 'scribunto',\n",
       " 'sections',\n",
       " 'selectors',\n",
       " 'sets',\n",
       " 'settings',\n",
       " 'shared',\n",
       " 'signedness',\n",
       " 'skins',\n",
       " 'sources',\n",
       " 'spaces',\n",
       " 'speranto',\n",
       " 'ss',\n",
       " 'ssociative',\n",
       " 'startup',\n",
       " 'statements',\n",
       " 'stating',\n",
       " 'stored',\n",
       " 'storing',\n",
       " 'streams',\n",
       " 'structures',\n",
       " 'styled',\n",
       " 'styles',\n",
       " 'subsets',\n",
       " 'svg',\n",
       " 'symbols',\n",
       " 'systems',\n",
       " 'tabs',\n",
       " 'tagline',\n",
       " 'taliano',\n",
       " 'tandard',\n",
       " 'tandardisation',\n",
       " 'tem',\n",
       " 'templateargumentsize',\n",
       " 'tep',\n",
       " 'terminated',\n",
       " 'terms',\n",
       " 'teven',\n",
       " 'texts',\n",
       " 'tffind',\n",
       " 'ther',\n",
       " 'things',\n",
       " 'timestamp',\n",
       " 'timeusage',\n",
       " 'timingprofile',\n",
       " 'tina',\n",
       " 'toc',\n",
       " 'tokens',\n",
       " 'toolbar',\n",
       " 'tools',\n",
       " 'trademark',\n",
       " 'transientcontent',\n",
       " 'translating',\n",
       " 'tream',\n",
       " 'tring',\n",
       " 'truct',\n",
       " 'tructure',\n",
       " 'ttempt',\n",
       " 'ttl',\n",
       " 'ttribution',\n",
       " 'txt',\n",
       " 'types',\n",
       " 'uadruple',\n",
       " 'ublish',\n",
       " 'ublished',\n",
       " 'ubmit',\n",
       " 'ubtyping',\n",
       " 'uery',\n",
       " 'uggest',\n",
       " 'ugust',\n",
       " 'ul',\n",
       " 'uls',\n",
       " 'uly',\n",
       " 'uman',\n",
       " 'umeric',\n",
       " 'une',\n",
       " 'units',\n",
       " 'unsourced',\n",
       " 'unt',\n",
       " 'upload',\n",
       " 'url',\n",
       " 'uropean',\n",
       " 'urrent',\n",
       " 'usa',\n",
       " 'usages',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'ussian',\n",
       " 'uth',\n",
       " 'utilities',\n",
       " 'utonym',\n",
       " 'utton',\n",
       " 'ux',\n",
       " 'values',\n",
       " 'variations',\n",
       " 'venska',\n",
       " 'vents',\n",
       " 'versample',\n",
       " 'vte',\n",
       " 'walltime',\n",
       " 'watchlist',\n",
       " 'wg',\n",
       " 'wiki',\n",
       " 'wikibase',\n",
       " 'wikidata',\n",
       " 'wikimedia',\n",
       " 'wikipedia',\n",
       " 'wikitext',\n",
       " 'wl',\n",
       " 'wmf',\n",
       " 'ws',\n",
       " 'www',\n",
       " 'xception',\n",
       " 'xtended',\n",
       " 'xterm',\n",
       " 'years',\n",
       " 'ynx',\n",
       " 'ype',\n",
       " 'yte']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many plural nouns and forms of the same verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the results of processing the URL http://news.bbc.co.uk/ using the regular\n",
    "expressions suggested above. You will see that there is still a fair amount of\n",
    "non-textual data there, particularly JavaScript commands. You may also find that\n",
    "sentence breaks have not been properly preserved. Define further regular expressions\n",
    "that improve the extraction of text from this web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_bbc = unknown(\"http://news.bbc.co.uk/\", regex='\\\\b[a-z]+\\\\b')\n",
    "len(unknown_bbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abs',\n",
       " 'accusations',\n",
       " 'adchoices',\n",
       " 'adding',\n",
       " 'ads',\n",
       " 'adverts',\n",
       " 'ageing',\n",
       " 'allegations',\n",
       " 'allowed',\n",
       " 'alsos',\n",
       " 'amp',\n",
       " 'antialiased',\n",
       " 'ap',\n",
       " 'api',\n",
       " 'app',\n",
       " 'arguments',\n",
       " 'arrests',\n",
       " 'arts',\n",
       " 'async',\n",
       " 'attacks',\n",
       " 'attributes',\n",
       " 'autocapitalize',\n",
       " 'autocomplete',\n",
       " 'autocorrect',\n",
       " 'auxclick',\n",
       " 'balatarin',\n",
       " 'bbc',\n",
       " 'bbccookies',\n",
       " 'bbcdotcom',\n",
       " 'bbci',\n",
       " 'bbcpage',\n",
       " 'bbcprivacy',\n",
       " 'bbcredirection',\n",
       " 'bbcthree',\n",
       " 'bbcuser',\n",
       " 'bbcworldwide',\n",
       " 'beats',\n",
       " 'became',\n",
       " 'believed',\n",
       " 'biowaste',\n",
       " 'bitesize',\n",
       " 'blog',\n",
       " 'bramstein',\n",
       " 'branding',\n",
       " 'browsers',\n",
       " 'btn',\n",
       " 'bubbles',\n",
       " 'bugs',\n",
       " 'bullied',\n",
       " 'bundles',\n",
       " 'calc',\n",
       " 'callback',\n",
       " 'called',\n",
       " 'cannabis',\n",
       " 'carpeted',\n",
       " 'catches',\n",
       " 'cbbc',\n",
       " 'cbeebies',\n",
       " 'cc',\n",
       " 'ccauds',\n",
       " 'cdn',\n",
       " 'cf',\n",
       " 'changed',\n",
       " 'charset',\n",
       " 'chartbeat',\n",
       " 'checksum',\n",
       " 'children',\n",
       " 'choices',\n",
       " 'clasps',\n",
       " 'closeable',\n",
       " 'cmd',\n",
       " 'co',\n",
       " 'com',\n",
       " 'comments',\n",
       " 'comp',\n",
       " 'config',\n",
       " 'configurable',\n",
       " 'conservatives',\n",
       " 'const',\n",
       " 'contexts',\n",
       " 'cookie',\n",
       " 'cookies',\n",
       " 'cps',\n",
       " 'crampons',\n",
       " 'crowds',\n",
       " 'crwdcntrl',\n",
       " 'css',\n",
       " 'cta',\n",
       " 'ctrl',\n",
       " 'cy',\n",
       " 'dcdcdc',\n",
       " 'debug',\n",
       " 'declarations',\n",
       " 'deps',\n",
       " 'detectview',\n",
       " 'determining',\n",
       " 'dialog',\n",
       " 'dist',\n",
       " 'dns',\n",
       " 'docs',\n",
       " 'douban',\n",
       " 'dp',\n",
       " 'drops',\n",
       " 'earlier',\n",
       " 'echoclient',\n",
       " 'edr',\n",
       " 'effectivemeasure',\n",
       " 'elem',\n",
       " 'elements',\n",
       " 'eles',\n",
       " 'emp',\n",
       " 'endif',\n",
       " 'enriched',\n",
       " 'env',\n",
       " 'envs',\n",
       " 'eol',\n",
       " 'erasing',\n",
       " 'eslint',\n",
       " 'euro',\n",
       " 'evt',\n",
       " 'exec',\n",
       " 'executing',\n",
       " 'expires',\n",
       " 'expressions',\n",
       " 'facebook',\n",
       " 'features',\n",
       " 'feeds',\n",
       " 'feet',\n",
       " 'fff',\n",
       " 'files',\n",
       " 'flexbox',\n",
       " 'flies',\n",
       " 'flipboard',\n",
       " 'footerbutton',\n",
       " 'forces',\n",
       " 'frameworks',\n",
       " 'gb',\n",
       " 'gd',\n",
       " 'geolocation',\n",
       " 'getcount',\n",
       " 'gets',\n",
       " 'github',\n",
       " 'google',\n",
       " 'googleplus',\n",
       " 'googletag',\n",
       " 'googletagservices',\n",
       " 'gpt',\n",
       " 'grayscale',\n",
       " 'gs',\n",
       " 'gscontxt',\n",
       " 'gsurl',\n",
       " 'has',\n",
       " 'hatena',\n",
       " 'haveyoursay',\n",
       " 'headerbutton',\n",
       " 'hf',\n",
       " 'highlights',\n",
       " 'hits',\n",
       " 'homepage',\n",
       " 'homes',\n",
       " 'hometown',\n",
       " 'hopes',\n",
       " 'hostname',\n",
       " 'hotspot',\n",
       " 'hours',\n",
       " 'href',\n",
       " 'html',\n",
       " 'http',\n",
       " 'https',\n",
       " 'icons',\n",
       " 'idcta',\n",
       " 'ignored',\n",
       " 'iife',\n",
       " 'img',\n",
       " 'imrworldwide',\n",
       " 'inbox',\n",
       " 'info',\n",
       " 'init',\n",
       " 'inline',\n",
       " 'instagram',\n",
       " 'instanceof',\n",
       " 'int',\n",
       " 'investors',\n",
       " 'invoking',\n",
       " 'iplayer',\n",
       " 'islands',\n",
       " 'issues',\n",
       " 'istats',\n",
       " 'items',\n",
       " 'javascript',\n",
       " 'jira',\n",
       " 'jobs',\n",
       " 'jquery',\n",
       " 'js',\n",
       " 'jsonp',\n",
       " 'jssignals',\n",
       " 'keyframes',\n",
       " 'keyline',\n",
       " 'keywords',\n",
       " 'killings',\n",
       " 'labels',\n",
       " 'lang',\n",
       " 'lazyload',\n",
       " 'lazyloaded',\n",
       " 'lazyloading',\n",
       " 'len',\n",
       " 'liars',\n",
       " 'lib',\n",
       " 'linejoin',\n",
       " 'livejournal',\n",
       " 'localnews',\n",
       " 'locations',\n",
       " 'logo',\n",
       " 'lotame',\n",
       " 'ls',\n",
       " 'ltr',\n",
       " 'lx',\n",
       " 'lxadverts',\n",
       " 'matches',\n",
       " 'max',\n",
       " 'maxlength',\n",
       " 'meneame',\n",
       " 'menuitem',\n",
       " 'metadata',\n",
       " 'minutes',\n",
       " 'miterlimit',\n",
       " 'mixi',\n",
       " 'modules',\n",
       " 'moimir',\n",
       " 'morebutton',\n",
       " 'moz',\n",
       " 'mozart',\n",
       " 'mozilla',\n",
       " 'ms',\n",
       " 'msie',\n",
       " 'multi',\n",
       " 'mybbc',\n",
       " 'named',\n",
       " 'nations',\n",
       " 'nav',\n",
       " 'navpromo',\n",
       " 'newsdotcom',\n",
       " 'northernireland',\n",
       " 'noscript',\n",
       " 'notifications',\n",
       " 'nowrap',\n",
       " 'ns',\n",
       " 'nw',\n",
       " 'objects',\n",
       " 'occurred',\n",
       " 'odnoklassniki',\n",
       " 'ol',\n",
       " 'oldonload',\n",
       " 'onload',\n",
       " 'onscroll',\n",
       " 'optimizely',\n",
       " 'options',\n",
       " 'org',\n",
       " 'osx',\n",
       " 'owns',\n",
       " 'padded',\n",
       " 'pageshow',\n",
       " 'params',\n",
       " 'pathname',\n",
       " 'paths',\n",
       " 'payloads',\n",
       " 'pe',\n",
       " 'persisted',\n",
       " 'personalisation',\n",
       " 'perspectives',\n",
       " 'pictures',\n",
       " 'pinterest',\n",
       " 'pixels',\n",
       " 'placeholder',\n",
       " 'plurk',\n",
       " 'png',\n",
       " 'policemen',\n",
       " 'polyfill',\n",
       " 'preferences',\n",
       " 'prefetch',\n",
       " 'progid',\n",
       " 'promis',\n",
       " 'promo',\n",
       " 'protesters',\n",
       " 'protests',\n",
       " 'provides',\n",
       " 'ptrt',\n",
       " 'pw',\n",
       " 'px',\n",
       " 'qa',\n",
       " 'qq',\n",
       " 'questions',\n",
       " 'ransacked',\n",
       " 'reactid',\n",
       " 'reactroot',\n",
       " 'reeldotcom',\n",
       " 'registers',\n",
       " 'renamed',\n",
       " 'renren',\n",
       " 'replacing',\n",
       " 'requests',\n",
       " 'rgba',\n",
       " 'says',\n",
       " 'searchbox',\n",
       " 'seconds',\n",
       " 'sections',\n",
       " 'settings',\n",
       " 'sharedmodules',\n",
       " 'ships',\n",
       " 'shocked',\n",
       " 'shocks',\n",
       " 'shouldn',\n",
       " 'shows',\n",
       " 'signed',\n",
       " 'sites',\n",
       " 'slips',\n",
       " 'slots',\n",
       " 'smp',\n",
       " 'soundcloud',\n",
       " 'sounds',\n",
       " 'specified',\n",
       " 'spellcheck',\n",
       " 'sponsored',\n",
       " 'sr',\n",
       " 'src',\n",
       " 'srcset',\n",
       " 'ssa',\n",
       " 'ssc',\n",
       " 'stacked',\n",
       " 'stackoverflow',\n",
       " 'stats',\n",
       " 'statusbar',\n",
       " 'steps',\n",
       " 'stories',\n",
       " 'stormed',\n",
       " 'str',\n",
       " 'stretches',\n",
       " 'stuns',\n",
       " 'styles',\n",
       " 'stylesheet',\n",
       " 'subnav',\n",
       " 'substring',\n",
       " 'subtree',\n",
       " 'suggestions',\n",
       " 'svg',\n",
       " 'swfobject',\n",
       " 'tabindex',\n",
       " 'tabs',\n",
       " 'tags',\n",
       " 'takes',\n",
       " 'teenagers',\n",
       " 'templates',\n",
       " 'testfeature',\n",
       " 'tests',\n",
       " 'things',\n",
       " 'thresholds',\n",
       " 'timeout',\n",
       " 'timestamp',\n",
       " 'tp',\n",
       " 'tps',\n",
       " 'trafalgar',\n",
       " 'translations',\n",
       " 'traveldotcom',\n",
       " 'trusted',\n",
       " 'turtles',\n",
       " 'tv',\n",
       " 'typeof',\n",
       " 'uas',\n",
       " 'ui',\n",
       " 'uid',\n",
       " 'uk',\n",
       " 'ul',\n",
       " 'unescape',\n",
       " 'unobserve',\n",
       " 'updated',\n",
       " 'uppercase',\n",
       " 'uri',\n",
       " 'url',\n",
       " 'usingthebbc',\n",
       " 'utf',\n",
       " 'utils',\n",
       " 'var',\n",
       " 'vehicles',\n",
       " 'versions',\n",
       " 'views',\n",
       " 'visited',\n",
       " 'vkontakte',\n",
       " 'waf',\n",
       " 'waits',\n",
       " 'walked',\n",
       " 'watches',\n",
       " 'webkit',\n",
       " 'webmodule',\n",
       " 'webmodules',\n",
       " 'weibo',\n",
       " 'whales',\n",
       " 'ws',\n",
       " 'wwhp',\n",
       " 'wwscripts',\n",
       " 'www',\n",
       " 'xl',\n",
       " 'xml',\n",
       " 'xs',\n",
       " 'xxl',\n",
       " 'years',\n",
       " 'youtube']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_bbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you able to write a regular expression to tokenize text in such a way that the\n",
    "word don’t is tokenized into do and n’t? Explain why this regular expression won’t\n",
    "work: «n't|\\w+»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['don', 't']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"n't|\\w+\", \"don't\")  # + is a greedy quantifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bla', 'do', \"n't\", 'blabla']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\\\bdo|n't\\\\b|\\w+\", \"bla don't blabla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to write code to convert text into hAck3r, using regular expressions and\n",
    "substitution, where e → 3, i → 1, o → 0, l → |, s → 5, . → 5w33t!, ate → 8. Normalize\n",
    "the text to lowercase before converting it. Add more substitutions of your own.\n",
    "Now try to map s to two different values: $ for word-initial s, and 5 for wordinternal\n",
    "s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Examine the results of processing the URL http://news.bbc.co.uk/ \n",
    "using the regular expressions suggested above. You will see that there is still a \n",
    "fair amount of non-textual data there, particularly JavaScript commands.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3xam1n3 th3 r35u|t5 of proc3551ng th3 ur| http://n3w55w33t!bbc5w33t!co5w33t!uk/ \\nu51ng th3 r3gu|ar 3xpr3551on5 5ugg35t3d abov35w33t! you w1|| 533 that th3r3 15 5t1|| a \\nfa1r amount of non-t3xtua| data th3r3, part1cu|ar|y java5cr1pt command55w33t!'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_v01 = (\n",
    "    text\n",
    "    .lower()\n",
    "    .replace('e', '3')\n",
    "    .replace('i', '1')\n",
    "    .replace('l', '|')\n",
    "    .replace('s', '5')\n",
    "    .replace('.', '5w33t!')\n",
    "    .replace('ate', '8')\n",
    ")\n",
    "text_v01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3xam1n3 th3 r35u|t5 of proc3551ng th3 ur| http://n3w55w33t!bbc5w33t!co5w33t!uk/ \\nu51ng th3 r3gu|ar 3xpr3551on5 $ugg35t3d abov35w33t! you w1|| $33 that th3r3 15 $t1|| a \\nfa1r amount of non-t3xtua| data th3r3, part1cu|ar|y java5cr1pt command55w33t!'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_v02 = (\n",
    "    text.lower()\n",
    "    .replace('e', '3')\n",
    "    .replace('i', '1')\n",
    "    .replace('l', '|')\n",
    "    .replace('.', '5w33t!')\n",
    "    .replace('ate', '8')\n",
    ")\n",
    "text_v02 = re.sub('\\\\bs', '$', text_v02)\n",
    "text_v02 = re.sub('s', '5', text_v02)\n",
    "text_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
