{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit Steven Bird, mEwan Klein, and Edward Loper http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08 - Analyzing Sentence Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Some Grammatical Dilemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic Data and Unlimited Possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will adopt the formal framework of “generative grammar,” in which a “language” is considered to be nothing more than an enormous collection of all grammatical sentences, and a grammar is a formal notation that can be used for “generating” the members of this set. Grammars use recursive productions of the form S → S and S, as we will explore in Section 8.3. In Chapter 10 we will extend this, to\n",
    "automatically build up the meaning of a sentence out of the meanings of its parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubiquitous Ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a closer look at the ambiguity in the phrase: I shot an elephant in my pajamas.First we need to define a simple grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 What's the Use of Syntax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  8.3 Context-Free Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start off by looking at a simple context-free grammar (CFG). By convention, the lefthand side of the first production is the start-symbol of the grammar, typically S, and all well-formed trees must have this symbol as their root label. In NLTK, contextfree grammars are defined in the nltk.grammar module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    VP -> V NP | V NP PP\n",
    "    PP -> P NP\n",
    "    V -> \"saw\" | \"ate\" | \"walked\"\n",
    "    NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "    Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "    N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "    P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Your Own Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in experimenting with writing CFGs, you will find it helpful to create and edit your grammar in a text file, say, mygrammar.cfg. You can then load it into NLTK and parse with it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mygrammar.cfg\n"
     ]
    }
   ],
   "source": [
    "%%file mygrammar.cfg\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm mygrammar.cfg\n",
    "# !del /f mygrammar.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursion in Syntactic Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The production Nom -> Adj Nom (where Nom is the category of nominals) involves direct recursion on the category Nom, whereas indirect recursion on S arises from the combination of two productions, namely S -> NP VP and VP -> V S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "    S  -> NP VP\n",
    "    NP -> Det Nom | PropN\n",
    "    Nom -> Adj Nom | N\n",
    "    VP -> V Adj | V NP | V S | V NP PP\n",
    "    PP -> P NP\n",
    "    PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "    Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
    "    V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "    P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"the angry bear chased the frightened little squirrel\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Chatterer said Buster thought the tree was tall\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Parsing with Context-Free Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar. A grammar is a declarative specification of well-formedness—it is actually just a string, not a program.\n",
    "A parser is a procedural interpretation of the grammar. It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Descent Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest kind of parser interprets a grammar as a specification of how to break a high-level goal into several lower-level subgoals. The top-level goal is to find an S. The S → NP VP production permits the parser to replace this goal with two subgoals: find an NP, then find a VP. Each of these subgoals can be replaced in turn by sub-subgoals, using productions that have NP and VP on their lefthand side. Eventually, this expansion process leads to subgoals such as: find the word telescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive descent parsing has **three key shortcomings**.\n",
    "1. First, left-recursive productions like NP -> NP PP send it into an infinite loop.\n",
    "2. Second, the parser wastes a lot of time considering words and structures that do not correspond to the input sentence.\n",
    "3. Third, the backtracking process may discard parsed constituents that will need to be rebuilt again later.  For example, backtracking over VP -> V NP will discard the subtree created for the NP. If the parser then proceeds with VP -> V NP PP, then the NP subtree must be created all over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive descent parsing is a kind of **top-down** parsing. Top-down parsers use a grammar to **predict** what the input will be, before inspecting the input! However, since the input is available to the parser all along, it would be more sensible to consider the input sentence from the very beginning. This approach is called **bottom-up** parsing, and we will see an example in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift-Reduce Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple kind of bottom-up parser is the shift-reduce parser. In common with all bottom-up parsers, a shift-reduce parser tries to find sequences of words and phrases that correspond to the righthand side of a grammar production, and replace them with the lefthand side, until the whole sentence is reduced to an S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "nltk.app.srparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A shift-reduce parser can reach a dead end and fail to find any parse, even if the input sentence is well-formed according to the grammar**. When this happens, no input remains, and the stack contains items which cannot be reduced to an S. The problem arises because there are choices made earlier that cannot be undone by the parser (although users of the graphical demonstration can undo their choices). There are two kinds of choices to be made by the parser:<div>\n",
    "(a) which reduction to do when more than one is possible.<div>\n",
    "(b) whether to shift or reduce when either action is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A shift-reduce parser may be extended to implement policies for resolving such conflicts**. For example, it may address shift-reduce conflicts by shifting only when no reductions are possible, and it may address reduce-reduce conflicts by favoring the reduction operation that removes the most items from the stack. (A generalization of shift-reduce parser, a \"lookahead LR parser\", is commonly used in programming language compilers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "1. The advantage of shift-reduce parsers over recursive descent parsers is that they only build structure that corresponds to the words in the input.\n",
    "2. Furthermore, they only build each sub-structure once, e.g. NP(Det(the), N(man)) is only built and pushed onto the stack a single time, regardless of whether it will later be used by the VP -> V NP PP reduction or the NP -> NP PP reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Left-Corner Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with the recursive descent parser is that it goes into an infinite loop when it encounters a left-recursive production. This is because it applies the grammar productions blindly, without considering the actual input sentence. A left-corner parser is a hybrid between the bottom-up and top-down approaches we have seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A left-corner parser is a top-down parser with bottom-up filtering**. Unlike an ordinary recursive descent parser, it does not get trapped in left recursive productions. Before starting its work, a left-corner parser preprocesses the context-free grammar to build a table where each row contains two cells, the first holding a non-terminal, and the second holding the collection of possible left corners of that non-terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.LeftCornerChartParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-Formed Substring Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple parsers discussed in the previous sections suffer from limitations in both completeness and efficiency. In order to remedy these, we will apply the algorithm design technique of dynamic programming to the parsing problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[V -> 'shot']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groucho_grammar.productions(rhs=text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
    "    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1, nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1, nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" %\n",
    "                              (start, nt1, mid, nt2, end, start, index[(nt1, nt2)], end))\n",
    "    return wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(wfst, tokens):\n",
    "    print('\\nWFST ' + ' '.join((\"%-4d\" % i) for i in range(1, len(wfst))))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d   \" % i, end=\" \")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" % (wfst[i][j] or '.'), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"I shot an elephant in my pajamas\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfst0 = init_wfst(tokens, groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1    2    3    4    5    6    7   \n",
      "0    NP   .    .    .    .    .    .    \n",
      "1    .    V    .    .    .    .    .    \n",
      "2    .    .    Det  .    .    .    .    \n",
      "3    .    .    .    N    .    .    .    \n",
      "4    .    .    .    .    P    .    .    \n",
      "5    .    .    .    .    .    Det  .    \n",
      "6    .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1    2    3    4    5    6    7   \n",
      "0    NP   .    .    S    .    .    S    \n",
      "1    .    V    .    VP   .    .    VP   \n",
      "2    .    .    Det  NP   .    .    .    \n",
      "3    .    .    .    N    .    .    .    \n",
      "4    .    .    .    .    P    .    PP   \n",
      "5    .    .    .    .    .    Det  NP   \n",
      "6    .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Det [3]   N [4] ==> [2]  NP [4]\n",
      "[5] Det [6]   N [7] ==> [5]  NP [7]\n",
      "[1]   V [2]  NP [4] ==> [1]  VP [4]\n",
      "[4]   P [5]  NP [7] ==> [4]  PP [7]\n",
      "[0]  NP [1]  VP [4] ==> [0]   S [4]\n",
      "[1]  VP [4]  PP [7] ==> [1]  VP [7]\n",
      "[0]  NP [1]  VP [7] ==> [0]   S [7]\n"
     ]
    }
   ],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WFST's have several shortcomings.**\n",
    "1. First, as you can see, the WFST is not itself a parse tree, so the technique is strictly speaking **recognizing** that a sentence is admitted by a grammar, rather than parsing it. \n",
    "2. Second, it requires every non-lexical grammar production to be binary. Although it is possible to convert an arbitrary CFG into this form, we would prefer to use an approach without such a requirement.\n",
    "3. Third, as a bottom-up approach it is potentially wasteful, being able to propose constituents in locations that would not be licensed by the grammar.\n",
    "4. Finally, the WFST did not represent the structural ambiguity in the sentence (i.e. the two verb phrase readings). The VP in cell (1, 7) was actually entered twice, once for a V NP reading, and once for a VP PP reading. These are different hypotheses, and the second overwrote the first (as it happens this didn't matter since the left hand side was the same.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart parsers use a slighly richer data structure and some interesting algorithms to solve these problems (see the Further Reading section at the end of this chapter for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.app.chartparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Dependencies and Dependency Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrase structure grammar is concerned with how words and sequences of words combine\n",
    "to form constituents. A distinct and complementary approach, dependency\n",
    "grammar, focuses instead on how words relate to other words. Dependency is a binary\n",
    "asymmetric relation that holds between a head and its dependents. The head of a\n",
    "sentence is usually taken to be the tensed verb, and every other word is either dependent\n",
    "on the sentence head or connects to it through a path of dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'shot' -> 'I' | 'elephant' | 'in'\n",
    "    'elephant' -> 'an' | 'in'\n",
    "    'in' -> 'pajamas'\n",
    "    'pajamas' -> 'my'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an (in (pajamas my))))\n",
      "(shot I (elephant an) (in (pajamas my)))\n"
     ]
    }
   ],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)\n",
    "for tree in trees:\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valency and the Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Grammar Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing builds trees over sentences, according to a phrase structure grammar. Now, all\n",
    "the examples we gave earlier only involved toy grammars containing a handful of productions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebanks and Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus module defines the treebank corpus reader, which contains a 10% sample\n",
    "of the Penn Treebank Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tree(tree):\n",
    "    child_nodes = [child.label() for child in tree\n",
    "                   if isinstance(child, nltk.Tree)]\n",
    "    return  (tree.label() == 'VP') and ('S' in child_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree(',', [',']), Tree('``', ['``']), Tree('S', [Tree('NP-SBJ', [Tree('DT', ['This'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('DT', ['an']), Tree('JJ', ['old']), Tree('NN', ['story'])])])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree('S', [Tree('-NONE-', ['*T*-1'])])]),\n",
       " Tree('VP', [Tree('VBN', ['expected']), Tree('S', [Tree('-NONE-', ['*?*'])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree('S', [Tree('-NONE-', ['*T*-1'])])])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "[subtree for tree in treebank.parsed_sents()\n",
    "         for subtree in tree.subtrees(filter_tree)][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import ppattach\n",
    "\n",
    "entries = ppattach.attachments('training')\n",
    "table = defaultdict(lambda: defaultdict(set))\n",
    "for entry in entries:\n",
    "    key = entry.noun1 + '-' + entry.prep + '-' + entry.noun2\n",
    "    table[key][entry.attachment].add(entry.verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%-below-level N: ['left'] V: ['be']\n",
      "%-from-year N: ['was'] V: ['declined', 'dropped', 'fell', 'grew', 'increased', 'plunged', 'rose', 'was']\n",
      "%-in-August N: ['was'] V: ['climbed', 'fell', 'leaping', 'rising', 'rose']\n",
      "%-in-September N: ['increased'] V: ['climbed', 'declined', 'dropped', 'edged', 'fell', 'grew', 'plunged', 'rose', 'slipped']\n",
      "%-in-week N: ['declined'] V: ['was']\n",
      "%-to-% N: ['add', 'added', 'backed', 'be', 'cut', 'go', 'grow', 'increased', 'increasing', 'is', 'offer', 'plummet', 'reduce', 'rejected', 'rise', 'risen', 'shaved', 'wants', 'yield', 'zapping'] V: ['fell', 'rise', 'slipped']\n",
      "%-to-million N: ['declining'] V: ['advanced', 'climbed', 'cutting', 'declined', 'declining', 'dived', 'dropped', 'edged', 'fell', 'gained', 'grew', 'increased', 'jump', 'jumped', 'plunged', 'rising', 'rose', 'slid', 'slipped', 'soared', 'tumbled']\n",
      "1-to-21 N: ['dropped'] V: ['dropped']\n",
      "1-to-33 N: ['gained'] V: ['dropped', 'fell', 'jumped']\n",
      "1-to-4 N: ['added'] V: ['gained']\n",
      "1-to-47 N: ['jumped'] V: ['added', 'rose']\n",
      "1-to-point N: ['ended'] V: ['fell', 'rose']\n",
      "3-to-17 N: ['lost'] V: ['lost']\n",
      "500,000-in-fines N: ['paid'] V: ['paid']\n",
      "6.9-on-scale N: ['registered'] V: ['registered']\n",
      "access-to-AZT N: ['had'] V: ['had']\n",
      "access-to-arena N: ['permits'] V: ['lack']\n",
      "activity-in-part N: ['showed'] V: ['attributed']\n",
      "agreement-in-principle N: ['reached'] V: ['reached']\n",
      "agreement-with-Inc. N: ['announced', 'signed'] V: ['signed']\n",
      "agreement-with-creditors N: ['reached'] V: ['nearing']\n",
      "agreement-with-regulators N: ['presages', 'reach'] V: ['reach']\n",
      "aid-to-Contras N: ['renewing'] V: ['renewing']\n",
      "alliance-with-GM N: ['discussing', 'wrapping'] V: ['forge', 'have', 'negotiating']\n",
      "approval-for-drug N: ['granted'] V: ['obtain']\n",
      "attention-to-comments N: ['paid'] V: ['paid']\n",
      "attention-to-concerns N: ['pay'] V: ['show']\n",
      "attention-to-reports N: ['paid'] V: ['pay']\n",
      "bid-for-company N: ['fend', 'launch'] V: ['made', 'make']\n",
      "bid-for-million N: ['finance'] V: ['had']\n",
      "bids-for-company N: ['submitted'] V: ['solicit']\n",
      "billion-in-cash N: ['pay', 'raise'] V: ['raise']\n",
      "billion-of-bills N: ['sell', 'sold'] V: ['sold']\n",
      "billion-over-years N: ['total'] V: ['spent']\n",
      "billion-to-billion N: ['cause', 'place'] V: ['increased', 'rose']\n",
      "business-to-firms N: ['cutting'] V: ['give', 'transfer']\n",
      "business-with-them N: ['cease'] V: ['do']\n",
      "cap-on-amount N: ['eliminate'] V: ['places']\n",
      "cents-to-cents N: ['be', 'recovering'] V: ['fell', 'rose']\n",
      "change-in-earnings N: ['had'] V: ['had']\n",
      "changes-for-% N: ['measures'] V: ['measures', 'monitors']\n",
      "charge-in-quarter N: ['took'] V: ['had', 'included', 'incur', 'take', 'took']\n",
      "collar-on-trading N: ['re-establishing'] V: ['reinstating']\n",
      "commitments-from-banks N: ['secured', 'won'] V: ['obtained']\n",
      "competition-from-competitors N: ['faced'] V: ['fend']\n",
      "competition-in-production N: ['reduce'] V: ['reduce']\n",
      "contract-for-parts N: ['awarded', 'given', 'won'] V: ['received']\n",
      "contract-for-support N: ['awarded', 'issued'] V: ['received']\n",
      "contract-from-Co. N: ['received'] V: ['won']\n",
      "contract-with-Warner N: ['violates'] V: ['terminate']\n",
      "control-of-Inc. N: ['took'] V: ['seek']\n",
      "decline-for-quarter N: ['posted'] V: ['reported']\n",
      "decline-in-August N: ['followed', 'following', 'recorded'] V: ['following']\n",
      "decline-in-earnings N: ['alleviate', 'report', 'reported'] V: ['expects']\n",
      "declines-in-prices N: ['reflect'] V: ['had']\n",
      "disputes-with-company N: ['resolve'] V: ['resolve']\n",
      "domestic-production-through-July N: ['includes'] V: ['includes']\n",
      "drop-in-earnings N: ['posted'] V: ['posted']\n",
      "drop-in-profit N: ['experienced', 'had', 'posted', 'reported', 'reporting'] V: ['posted']\n",
      "earnings-for-companies N: ['reported'] V: ['reported']\n",
      "earnings-for-quarter N: ['posting'] V: ['posted', 'report', 'reported']\n",
      "earnings-in-quarter N: ['projecting'] V: ['had']\n",
      "earnings-of-million N: ['had', 'include', 'posted', 'reported'] V: ['reported']\n",
      "effect-on-market N: ['had'] V: ['had']\n",
      "emphasis-on-quality N: ['be'] V: ['place']\n",
      "financing-for-buy-out N: ['deliver', 'get'] V: ['obtaining']\n",
      "floor-for-price N: ['establishes'] V: ['providing']\n",
      "foot-in-door N: ['wanted'] V: ['getting']\n",
      "funding-for-abortion N: ['supporting'] V: ['oppose']\n",
      "funds-for-station N: ['including', 'providing'] V: ['includes']\n",
      "gain-from-sale N: ['included', 'includes'] V: ['a-Includes', 'including', 'record', 'report']\n",
      "gain-in-profit N: ['posted', 'reported'] V: ['posted']\n",
      "head-to-head N: ['going'] V: ['go']\n",
      "impact-on-market N: ['have'] V: ['has', 'have']\n",
      "impact-on-markets N: ['had'] V: ['have']\n",
      "impact-on-results N: ['have'] V: ['have']\n",
      "income-for-quarter N: ['announcing'] V: ['report']\n",
      "increase-in-earnings N: ['reported'] V: ['posted']\n",
      "information-from-companies N: ['requested'] V: ['steal']\n",
      "inquiry-into-activities N: ['conducted'] V: ['drop']\n",
      "interest-in-company N: ['bought', 'have', 'holds', 'owning', 'retain'] V: ['represent']\n",
      "interest-in-metals N: ['create'] V: ['was']\n",
      "interest-on-loans N: ['computing'] V: ['pay']\n",
      "loans-to-China N: ['suspended'] V: ['resuming']\n",
      "loss-for-quarter N: ['announced', 'have', 'post', 'posted', 'reported', 'reporting'] V: ['post', 'report', 'reported']\n",
      "loss-in-quarter N: ['expect', 'had'] V: ['caused', 'had', 'posted', 'took']\n",
      "losses-in-years N: ['reported'] V: ['had']\n",
      "markets-in-stocks N: ['making'] V: ['make']\n",
      "million-before-tax N: ['reported'] V: ['contributed']\n",
      "million-for-initiative N: ['attached'] V: ['add']\n",
      "million-for-stake N: ['pay'] V: ['paid', 'pay', 'putting']\n",
      "million-from-funds N: ['commit'] V: ['raises']\n",
      "million-from-operations N: ['included'] V: ['reported']\n",
      "million-from-sale N: ['including'] V: ['take']\n",
      "million-in-payments N: ['make', 'owes', 'pay', 'receive'] V: ['fallen']\n",
      "million-of-debt N: ['add', 'borrow', 'consolidate', 'convert', 'downgraded', 'includes', 'pay', 'raise'] V: ['assume']\n",
      "million-on-revenue N: ['earned'] V: ['earned', 'was', 'were']\n",
      "million-on-sales N: ['earned'] V: ['earned', 'reach', 'totaled', 'was', 'were']\n",
      "million-to-million N: ['be', 'bills', 'cost', 'pump', 'sell', 'totaled'] V: ['declined', 'fell', 'spend', 'tumbled']\n",
      "month-in-time N: ['delivered'] V: ['delivered']\n",
      "net-on-revenue N: ['posted'] V: ['reported']\n",
      "nothing-about-it N: ['knew'] V: ['doing']\n",
      "offer-for-all N: ['begun', 'make'] V: ['begin']\n",
      "offer-for-shares N: ['began', 'extended'] V: ['launched', 'made']\n",
      "offer-for-stock N: ['extended'] V: ['make']\n",
      "offer-from-group N: ['rejected'] V: ['received']\n",
      "office-in-Worth N: ['Call'] V: ['has']\n",
      "pace-with-inflation N: ['keep', 'keeping'] V: ['keep']\n",
      "payment-on-million N: ['make'] V: ['make']\n",
      "payments-on-debt N: ['cover', 'make'] V: ['make']\n",
      "president-in-charge N: ['is', 'named'] V: ['been']\n",
      "pressure-on-government N: ['keep'] V: ['keep', 'put']\n",
      "pressure-on-prices N: ['suffered'] V: ['keep', 'put']\n",
      "price-for-incentives N: ['paid'] V: ['paid']\n",
      "prices-on-market N: ['push'] V: ['bring']\n",
      "profit-for-year N: ['report'] V: ['report']\n",
      "profit-from-discontinued N: ['had'] V: ['was']\n",
      "profit-in-quarter N: ['indicates'] V: ['produce', 'recorded']\n",
      "projections-for-year N: ['slashed'] V: ['exceed']\n",
      "provisions-for-loans N: ['taken'] V: ['made']\n",
      "rates-to-% N: ['boosting'] V: ['increase', 'pushed', 'raised']\n",
      "reporter-in-bureau N: ['is'] V: ['is']\n",
      "restrictions-on-use N: ['waiving'] V: ['impose']\n",
      "revenue-for-year N: ['projected'] V: ['had']\n",
      "revenue-in-quarter N: ['expects'] V: ['had']\n",
      "sales-in-excess N: ['combined'] V: ['had']\n",
      "sales-in-quarter N: ['had'] V: ['increasing']\n",
      "sales-of-million N: ['expected', 'had', 'has', 'have', 'posted'] V: ['had']\n",
      "salvo-in-battle N: ['marking'] V: ['marking']\n",
      "services-for-customers N: ['offering'] V: ['provide']\n",
      "shareholder-in-bank N: ['become'] V: ['become']\n",
      "stake-in-Airlines N: ['acquiring', 'buy', 'raise'] V: ['buy']\n",
      "stake-in-Mixte N: ['bring'] V: ['boost']\n",
      "stake-in-Rally N: ['hold'] V: ['had']\n",
      "stake-in-company N: ['bought', 'building', 'built', 'buying', 'give', 'hold', 'obtaining', 'own', 'owns', 'raised', 'take'] V: ['accumulating', 'had', 'has', 'holds', 'own']\n",
      "stake-in-concern N: ['acquires', 'lowered'] V: ['retaining']\n",
      "stake-in-unit N: ['sell'] V: ['acquire']\n",
      "stake-in-venture N: ['has', 'hold', 'holds'] V: ['held']\n",
      "suit-against-Keating N: ['press'] V: ['brought']\n",
      "swings-in-market N: ['cause', 'create'] V: ['cause']\n",
      "system-for-city N: ['design'] V: ['design']\n",
      "system-in-Pakistan N: ['operate'] V: ['operate']\n",
      "time-for-Congress N: ['is'] V: ['buy', 'buys']\n",
      "venture-with-Co. N: ['started'] V: ['started']\n",
      "ventures-with-companies N: ['established'] V: ['form']\n",
      "verdict-in-case N: ['is', 'won'] V: ['won']\n",
      "volatility-in-stocks N: ['ignoring'] V: ['see']\n",
      "vote-on-issue N: ['allow'] V: ['prevent']\n",
      "way-for-declines N: ['open'] V: ['pave']\n",
      "writer-in-York N: ['is'] V: ['is']\n",
      "yen-to-yen N: ['shed'] V: ['advanced', 'fell', 'gained', 'lost', 'rose']\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(table):\n",
    "    if len(table[key]) > 1:\n",
    "        print(key, 'N:', sorted(table[key]['N']), 'V:', sorted(table[key]['V']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.sinica_treebank.parsed_sents()[3450].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pernicious Ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, as the coverage of the grammar increases and the length of the input\n",
    "sentences grows, the number of parse trees grows rapidly. In fact, it grows at an astronomical\n",
    "rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP V NP\n",
    "    NP -> NP Sbar\n",
    "    Sbar -> NP V\n",
    "    NP -> 'fish'\n",
    "    V -> 'fish'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP fish) (V fish) (NP (NP fish) (Sbar (NP fish) (V fish))))\n",
      "(S (NP (NP fish) (Sbar (NP fish) (V fish))) (V fish) (NP fish))\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"fish\"] * 5\n",
    "cp = nltk.ChartParser(grammar)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have just seen, dealing with ambiguity is a key challenge in developing broadcoverage\n",
    "parsers. Chart parsers improve the efficiency of computing multiple parses of\n",
    "the same sentences, but they are still overwhelmed by the sheer number of possible\n",
    "parses. Weighted grammars and probabilistic parsing algorithms have provided an effective\n",
    "solution to these problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give(t):\n",
    "    return t.label() == 'VP' and len(t) > 2 and t[1].label() == 'NP'\\\n",
    "           and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP')\\\n",
    "           and ('give' in t[0].leaves() or 'gave' in t[0].leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(t):\n",
    "    return ' '.join(token for token in t.leaves() if token[0] not in '*-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node(t, width):\n",
    "        output = \"%s %s: %s / %s: %s\" %\\\n",
    "            (sent(t[0]), t[1].label(), sent(t[1]), t[2].label(), sent(t[2]))\n",
    "        if len(output) > width:\n",
    "            output = output[:width] + \"...\"\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gave NP: the chefs / NP: a standing ovation\n",
      "give NP: advertisers / NP: discounts for maintaining or increasing ad sp...\n",
      "give NP: it / PP-DTV: to the politicians\n",
      "gave NP: them / NP: similar help\n",
      "give NP: them / NP: \n",
      "give NP: only French history questions / PP-DTV: to students in a Europe...\n",
      "give NP: federal judges / NP: a raise\n",
      "give NP: consumers / NP: the straight scoop on the U.S. waste crisis\n",
      "gave NP: Mitsui / NP: access to a high-tech medical product\n",
      "give NP: Mitsubishi / NP: a window on the U.S. glass industry\n",
      "give NP: much thought / PP-DTV: to the rates she was receiving , nor to ...\n",
      "give NP: your Foster Savings Institution / NP: the gift of hope and free...\n",
      "give NP: market operators / NP: the authority to suspend trading in futu...\n",
      "gave NP: quick approval / PP-DTV: to $ 3.18 billion in supplemental appr...\n",
      "give NP: the Transportation Department / NP: up to 50 days to review any...\n",
      "give NP: the president / NP: such power\n",
      "give NP: me / NP: the heebie-jeebies\n",
      "give NP: holders / NP: the right , but not the obligation , to buy a cal...\n",
      "gave NP: Mr. Thomas / NP: only a `` qualified '' rating , rather than ``...\n",
      "give NP: the president / NP: line-item veto power\n"
     ]
    }
   ],
   "source": [
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    for t in tree.subtrees(give):\n",
    "        print_node(t, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **probabilistic context free grammar** (or PCFG) is a context free grammar that associates a probability with each of its productions. It generates the same set of parses for a text that the corresponding context free grammar does, and assigns a probability to each parse. The probability of a parse generated by a PCFG is simply the product of the probabilities of the productions used to generate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to define a PCFG is to load it from a specially formatted string consisting of a sequence of weighted productions, where weights appear in brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S    -> NP VP              [1.0]\n",
    "    VP   -> TV NP              [0.4]\n",
    "    VP   -> IV                 [0.3]\n",
    "    VP   -> DatV NP NP         [0.3]\n",
    "    TV   -> 'saw'              [1.0]\n",
    "    IV   -> 'ate'              [1.0]\n",
    "    DatV -> 'gave'             [1.0]\n",
    "    NP   -> 'telescopes'       [0.8]\n",
    "    NP   -> 'Jack'             [0.2]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 9 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> TV NP [0.4]\n",
      "    VP -> IV [0.3]\n",
      "    VP -> DatV NP NP [0.3]\n",
      "    TV -> 'saw' [1.0]\n",
      "    IV -> 'ate' [1.0]\n",
      "    DatV -> 'gave' [1.0]\n",
      "    NP -> 'telescopes' [0.8]\n",
      "    NP -> 'Jack' [0.2]\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sometimes convenient to combine multiple productions into a single line, e.g. VP -> TV NP [0.4] | IV [0.3] | DatV NP NP [0.3]. In order to ensure that the trees generated by the grammar form a probability distribution, PCFG grammars impose the constraint that **all productions with a given left-hand side must have probabilities that sum to one**. The grammar above obeys this constraint: for S, there is only one production, with a probability of 1.0; for VP, 0.4+0.3+0.3=1.0; and for NP, 0.8+0.2=1.0. The parse tree returned by parse() includes probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Jack) (VP (TV saw) (NP telescopes))) (p=0.064)\n"
     ]
    }
   ],
   "source": [
    "viterbi_parser = nltk.ViterbiParser(grammar)\n",
    "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that parse trees are assigned probabilities, it no longer matters that there may be a huge number of possible parses for a given sentence. A parser will be responsible for finding the most likely parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
