{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 5.1 the new field appeared at the bottom of the entry. Modify this program so that it inserts the new subelement right after the lx field. (Hint: create the new cv field using Element('cv'), assign a text value to it, then use the insert() method of the parent element.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that deletes a specified field from a lexical entry. (We could use this to sanitize our lexical data before giving it to others, e.g. by removing fields containing irrelevant or uncertain content.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program that scans an HTML dictionary file to find entries having an illegal part-of-speech field, and reports the headword for each entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to find any parts of speech (ps field) that occurred less than ten times. Perhaps these are typing mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw a method for discovering cases of whole-word reduplication. Write a function to find words that may contain partial reduplication. Use the re.search() method, and the following regular expression: (..+)\\1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw a method for adding a cv field. There is an interesting issue with keeping this up-to-date when someone modifies the content of the lx field on which it is based. Write a version of this program to add a cv field, replacing any existing cv field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to add a new field syl which gives a count of the number of syllables in the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which displays the complete entry for a lexeme. When the lexeme is incorrectly spelled it should display the entry for the most similarly spelled lexeme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes a lexicon and finds which pairs of consecutive fields are most frequent (e.g. ps is often followed by pt). (This might help us to discover some of the structure of a lexical entry.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spreadsheet using office software, containing one lexical entry per row, consisting of a headword, a part of speech, and a gloss. Save the spreadsheet in CSV format. Write Python code to read the CSV file and print it in Toolbox format, using lx for the headword, ps for the part of speech, and gl for the gloss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index the words of Shakespeare's plays, with the help of nltk.Index. The resulting data structure should permit lookup on individual words such as music, returning a list of references to acts, scenes and speeches, of the form [(3, 2, 9), (5, 1, 23), ...], where (3, 2, 9) indicates Act 3 Scene 2 Speech 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a conditional frequency distribution which records the word length for each speech in The Merchant of Venice, conditioned on the name of the character, e.g. cfd['PORTIA'][12] would give us the number of speeches by Portia consisting of 12 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a comparative wordlist in CSV format, and write a program that prints those cognates having an edit-distance of at least three from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an index of those lexemes which appear in example sentences. Suppose the lexeme for a given entry is w. Then add a single cross-reference field xrf to this entry, referencing the headwords of other entries having example sentences containing w. Do this for all entries and save the result as a toolbox-format file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a recursive function to produce an XML representation for a tree, with non-terminals represented as XML elements, and leaves represented as text content, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAABtCAYAAAAcadU0AAAHd0lEQVR4nO2d3bGsKhCFTYoMTh7kcHIggRsGLycRYjEF7oONQsufzqAwLKu+2jXDiNr0EtS1cbGRZV1XAKZjgRgA2PhIDFoudlkIqaySypoODgqAO9SLQUu7LNJq77NQZi83SthFODEYq8QSlAPQOxVi0FYui5foBBNDjK3nEFaZ9w8UgBJZMZSSORgmcbHsJMQEQGfExaClXZaLwxwt8wl/p04AHqTYM9Qnr7FKeNcUPiWhANABxWuG+FDJWCX4d9pKqdkGMEQC41B5N4kn9Xa3aL9eWLhgXDkunsE44KEbAATEAAABMQBAQAwAEBADAATEAAABMQBAvCIGo0RozSCrhu9xCnxPxE9ZOYyyYlnsInXSqpK0yPvxij7ncdDzoQByCVRsfzaeEwOzgBslrQjsG9rK4En12d6h5bWHeFom7CFdsCWqUGZPTKnDeKUt8lt58HujrCh4w4LfZ7c/pwX/ATHELRlGSau0smK3cJTFcG7QwjYZx7qu3BOXO9sKZf9zFhRNZ8/omZdtgyXq+czNe7dtfakpkXn9JYt8TAwnO0xZDMntr/NZ8JuKIRdMo6RV5vj7eM9glJWnYcnx+23fWc+1+OXn5L3mwfL9XWHdYfwSFvmT4Aq94EkM5e0fxz2Hv6yNGCrGoGcRxMTw2TVDaZgUlDNxaLmce6E9oeI9z56QVT3DjZiWhkn7ieeTXvV+m45O854hFbxDDK6hKoZJl7dfWN8TAP9ttBfaE8q88P/eLB6x5Pb3j8XOKHFfDJNY8JtfM6SGSoEYXC/wdTF42zXKiuhQRFodHTKdhwa+YIwSDc+SFRb57LCHn4i0lbfG/vMMkdb1sbtJYVDdrdWg22V3Q8Jbqzcv4ox/AZwQVlIkwiols0Oc8+3fb929KljkE8Ow3P5d6xXmtODjoVukV1jX6xfrYHymFYPfO/EzZ91EB+DXmFYMAHAgBgAIiAEAAmIAgIAYACCGFAMs4KAF44jhqxbwOS3KIM8AYmhnAZ/NogzydC2GZyzgc/lvQJo+xfCGBXwCizLI06cYiMcs4JNYlEGersWwrq0t4BgigYPuxbDxbQv4nBZlkGcQMQDQHogBAAJiAICAGAAgIAYACIgBAAJiAM9Qmi6zA6YUQ8kC/u8Bi3jt+m3nZ3qK8AFoD/GPMY8YLlrA21vEP59LtitYfHkZj8X78T8zgRjuWcDbW8QL63tnw3ijZmYBX48zp1DGq4tPrJwuL9Vfim/2OLuI/2Ri+MQC3t4iXrl+YqxdNQu4m1HQfW+UVafJiuPlNfVXJVti/9+P/yxi+IIFvL1FvHL9aDIVZgH3kj02W2C5vG6W8fIwJG2WfD/+s4iB+MQC3t4iXrl+VAyVs4DfFkNd/bn4pve9l/if+WkxuAa7YwFvbxH/RAyVd5lui6H+LlZ6qJQ/vvfjf+bnxRALSskC/oRFvG79/DAoPQt4fH3+zrZ0ean+iqTL9grvx39iMYBnib1fon8gBgAIiAEAAmIAgIAYACAgBgAIiAE8AyzcffKuhdi3Orj79v534S3JuxbuvuaRhYW7L7qycMftDsWXuF/kUUs4LNwj0KeF2ygRPvHl1oichZvKpMq/53pPjuC90bHe6Pz0uKb+XHwPYOHugr4t3NrKvaG5Fyds4JSbNUjQyO9CMRT2lZvZquqHhbt/hrBw+43H664TQ7ZnWb1xdUyIJQt4rn5YuMejbwu3l2A88b4ohm2ow/ezwqJdWT8s3APRr4Xb1SHYhWJlQlUlKx23OQuieJeqov5cfGHh7pb+LNz5ZC9YuL0LYqnX4983vf31kzR6PKdjuFZ/Melg4QZgtbBwAzA4EAMABMQAAAExAEBADAAQvyOGASzCoG9+RAzXLMKtLMBgbMYRw5ctwi0swGBsBhBDG4twCwswGJuuxdDSItzCAgzGpk8xPGARbmEBBmPTpxiIlhbhFhZgMDZdi2Fd21mEW1iAwdh0L4aN71qE17WNBRiMzSBi4IxpEQZ9M6gYAPg+EAMABMQAAAExAEBADAAQEMOvAAv7xwwtBv95wiKUNcxodypfV5t8huCmQxF/7d9subKGWzlefyiXMisiPr8phtMs2sIu3lyl+2S5OlO+N4q2UgjP0cot36Vyx2bx0Kd5UhtYwC9b2CeLzxcYQAwxS0Q4aW90ncjZ6Jj5elv/mAL+6ucjgdwkW9dmm/v0+HliRZJwmvh8j67FkAxW5s32rhGiZ519PUoW+uySgDduutztn/cS8uTcpff9Tbct7JPEZw4xlOzS32psZuA7NXayfKsrHCaw9y1cPaZbv02YDX89Po3oUwxE2sKdmcI9U86HAVujaauN2x5v7FQ5u/h0pIYmNy3g9y3sc8RnKjG4hIjPos1nkd7OUtUXiJGGiTZ2tLz2NVSFIYC7A5MZ39+3sP9AfB6mezHkgsZnuODdcPzWYexlgv53f+yfy+X+rURhlamzgG/7V3MBec3C/ivxgRgmojgMSgILewsghtfQViZfGgjeAGIAgIAYACCiYsCCZcYFYsCChRaIAQsWWiAGLFhogRiwYKHlf6xppqFAQJmTAAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
